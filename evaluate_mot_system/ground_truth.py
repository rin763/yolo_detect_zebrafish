"""
Ground Truthç”Ÿæˆãƒ„ãƒ¼ãƒ« - 3ã¤ã®æ–¹æ³•ã‚’æä¾›
"""

import cv2
import numpy as np
from ultralytics import YOLO
import os
import json
from object_tracking import ObjectTracker

class GroundTruthGenerator:
    """
    æ–¹æ³•1: åŠè‡ªå‹•ç”Ÿæˆï¼ˆæ¨å¥¨ï¼‰
    - ç¾åœ¨ã®ãƒˆãƒ©ãƒƒã‚«ãƒ¼ã§åˆæœŸäºˆæ¸¬ã‚’ç”Ÿæˆ
    - ç›®è¦–ç¢ºèªã—ãªãŒã‚‰IDä¿®æ­£
    - æœ€ã‚‚åŠ¹ç‡çš„
    
    æ–¹æ³•2: å®Œå…¨è‡ªå‹•ç”Ÿæˆï¼ˆç°¡æ˜“è©•ä¾¡ç”¨ï¼‰
    - ç¾åœ¨ã®ãƒˆãƒ©ãƒƒã‚«ãƒ¼çµæœã‚’ãã®ã¾ã¾ä¿å­˜
    - åˆ¥ã®è¨­å®šã§å‹•ã‹ã—ãŸæ™‚ã¨ã®æ¯”è¼ƒç”¨
    
    æ–¹æ³•3: ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ç”Ÿæˆï¼ˆé•·æ™‚é–“å‹•ç”»ç”¨ï¼‰
    - Nç§’ã”ã¨ã«ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æŠ½å‡º
    - ä»£è¡¨çš„ãªãƒ•ãƒ¬ãƒ¼ãƒ ã®ã¿æ‰‹å‹•ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
    """
    
    # æœ€å¤§ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°æ•°ã®å®šæ•°ï¼ˆobject_tracking.pyã¨åŒã˜ï¼‰
    MAX_FISH = 10  # IDã¯1ã€œ10ã®ç¯„å›²ã§å‰²ã‚Šå½“ã¦ã‚‰ã‚Œã¾ã™
    
    def __init__(self, model_path, max_fish=None, use_lstm=True, enable_evaluation=False):
        """
        ObjectTrackerã‚’ä½¿ç”¨ã—ã¦Ground Truthã‚’ç”Ÿæˆ
        
        Args:
            model_path: YOLOãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹
            max_fish: æœ€å¤§ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°æ•°ï¼ˆNoneã®å ´åˆã¯MAX_FISHã‚’ä½¿ç”¨ï¼‰
            use_lstm: LSTMæ©Ÿèƒ½ã‚’ä½¿ç”¨ã™ã‚‹ã‹
            enable_evaluation: è©•ä¾¡æ©Ÿèƒ½ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã‹
        """
        if max_fish is None:
            max_fish = self.MAX_FISH
        
        self.max_fish = max_fish
        self.tracker = ObjectTracker(
            model_path=model_path,
            sequence_length=10,
            max_fish=max_fish,  # object_tracking.pyã¨åŒã˜è¨­å®š
            use_lstm=use_lstm,
            enable_evaluation=enable_evaluation
        )
        self.ground_truth_data = []
        self.id_corrections = {}  # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã‚‹IDä¿®æ­£è¨˜éŒ²
        self.deleted_ids_per_frame = {}  # {frame: [deleted_ids, ...]} å‰Šé™¤ã•ã‚ŒãŸIDã‚’è¨˜éŒ²
        self.last_mouse_x = None  # æœ€å¾Œã®ãƒã‚¦ã‚¹ã‚¯ãƒªãƒƒã‚¯ä½ç½®
        self.last_mouse_y = None
        
        print(f"Ground Truth Generator initialized with max_fish={max_fish}")
        print(f"IDs will be assigned from 1 to {max_fish}")
        
        # UIã®çŠ¶æ…‹
        self.current_frame_idx = 0
        self.paused = True
        self.selected_box = None
        
        # ãƒã‚¦ã‚¹ã‚¯ãƒªãƒƒã‚¯æ™‚ã®ä½ç½®
        self.mouse_x = None
        self.mouse_y = None
        self.mouse_clicked = False
        
    def method1_semi_automatic(self, video_path, output_path, review_interval=30):
        """
        æ–¹æ³•1: åŠè‡ªå‹•ç”Ÿæˆ
        
        ä½¿ã„æ–¹:
        1. ãƒˆãƒ©ãƒƒã‚«ãƒ¼ãŒè‡ªå‹•ã§IDã‚’å‰²ã‚Šå½“ã¦
        2. N ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã«ä¸€æ™‚åœæ­¢
        3. IDåˆ‡ã‚Šæ›¿ã‚ã‚ŠãŒã‚ã‚Œã°ä¿®æ­£
        4. ä¿®æ­£å†…å®¹ã‚’ä¿å­˜
        
        Args:
            video_path: å…¥åŠ›å‹•ç”»
            output_path: Ground Truthä¿å­˜å…ˆï¼ˆ.txtï¼‰
            review_interval: ä½•ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã«ãƒ¬ãƒ“ãƒ¥ãƒ¼ã™ã‚‹ã‹
        """
        print("\n=== æ–¹æ³•1: åŠè‡ªå‹•Ground Truthç”Ÿæˆï¼ˆObjectTrackerä½¿ç”¨ï¼‰===")
        print(f"æœ€å¤§ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°æ•°: {self.max_fish} (IDã¯1-{self.max_fish}ã§å‰²ã‚Šå½“ã¦)")
        print("æ“ä½œæ–¹æ³•:")
        print("  ãƒã‚¦ã‚¹: ãƒœãƒƒã‚¯ã‚¹ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦é¸æŠ")
        print("  A: æ–°è¦ç‰©ä½“ã‚’è¿½åŠ ï¼ˆæœ€å¾Œã®ãƒã‚¦ã‚¹ã‚¯ãƒªãƒƒã‚¯ä½ç½®ã€ã¾ãŸã¯ç”»é¢ä¸­å¤®ï¼‰")
        print("     - å‰Šé™¤ã•ã‚ŒãŸIDã‚’å„ªå…ˆçš„ã«å†åˆ©ç”¨ã—ã¾ã™")
        print("  D: é¸æŠã—ãŸç‰©ä½“ã‚’å‰Šé™¤ï¼ˆå‰Šé™¤ã•ã‚ŒãŸIDã¯å†åˆ©ç”¨å¯èƒ½ã«ãªã‚Šã¾ã™ï¼‰")
        print(f"  1-{min(9, self.max_fish)}: é¸æŠã—ãŸãƒœãƒƒã‚¯ã‚¹ã®IDã‚’å¤‰æ›´ï¼ˆã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ã®æ•°å­—ã‚­ãƒ¼ï¼‰")
        if self.max_fish == 10:
            print("  0: é¸æŠã—ãŸãƒœãƒƒã‚¯ã‚¹ã®IDã‚’10ã«å¤‰æ›´")
        print("  SPACE: ä¸€æ™‚åœæ­¢/å†ç”Ÿ")
        print("  â†’/N: æ¬¡ã®ãƒ•ãƒ¬ãƒ¼ãƒ ")
        print("  â†/P: å‰ã®ãƒ•ãƒ¬ãƒ¼ãƒ ")
        print("  S: ç¾åœ¨ã®çŠ¶æ…‹ã‚’ä¿å­˜")
        print("  Q: çµ‚äº†")
        
        cap = cv2.VideoCapture(video_path)
        # object_tracking.pyã¨åŒã˜ãƒ•ãƒ¬ãƒ¼ãƒ ã‚«ã‚¦ãƒ³ãƒˆæ–¹å¼ï¼ˆãƒ•ãƒ¬ãƒ¼ãƒ 1ã‹ã‚‰å§‹ã¾ã‚‹ï¼‰
        frame_count = 0  # åˆæœŸåŒ–ã¯0ï¼ˆobject_tracking.pyã¨åŒã˜ï¼‰
        temp_detections = []  # ä¸€æ™‚çš„ãªæ¤œå‡ºçµæœã‚’ä¿å­˜
        manual_detections = {}  # {frame: [(track_id, bbox), ...]}
        
        # ãƒã‚¦ã‚¹ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©ãƒ¼
        def mouse_callback(event, x, y, flags, param):
            if event == cv2.EVENT_LBUTTONDOWN:
                self.mouse_x = x
                self.mouse_y = y
                self.last_mouse_x = x  # æœ€å¾Œã®ã‚¯ãƒªãƒƒã‚¯ä½ç½®ã‚’è¨˜éŒ²
                self.last_mouse_y = y
                self.mouse_clicked = True
                print(f"ãƒã‚¦ã‚¹ã‚¯ãƒªãƒƒã‚¯: ({x}, {y})")
        
        cv2.namedWindow("Ground Truth Generator")
        cv2.setMouseCallback("Ground Truth Generator", mouse_callback)
        
        # å‹•ç”»ã®ç·ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ã‚’å–å¾—ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        print(f"å‹•ç”»ã®ç·ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {total_frames}")
        
        while cap.isOpened():
            # object_tracking.pyã¨åŒã˜æ–¹å¼ï¼šãƒ•ãƒ¬ãƒ¼ãƒ ã‚’èª­ã¿è¾¼ã‚€
            if not self.paused:
                ret, frame = cap.read()
                if not ret:
                    break
                frame_count += 1  # object_tracking.pyã¨åŒã˜ï¼šèª­ã¿è¾¼ã¿å¾Œã«ã‚«ã‚¦ãƒ³ãƒˆ
            else:
                # ä¸€æ™‚åœæ­¢ä¸­ï¼šç¾åœ¨ã®ãƒ•ãƒ¬ãƒ¼ãƒ ä½ç½®ã‚’å†èª­ã¿è¾¼ã¿
                # CAP_PROP_POS_FRAMESã¯0ãƒ™ãƒ¼ã‚¹ãªã®ã§ã€frame_count-1ã‚’æŒ‡å®š
                if frame_count == 0:
                    # æœ€åˆã®ãƒ•ãƒ¬ãƒ¼ãƒ ã®å ´åˆ
                    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
                    ret, frame = cap.read()
                    if not ret:
                        break
                    frame_count += 1
                else:
                    # frame_count > 0ã®å ´åˆã€frame_count-1ã®ä½ç½®ã‚’æŒ‡å®š
                    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_count - 1)
                    ret, frame = cap.read()
                    if not ret:
                        break
            
            # ObjectTrackerã§ã®æ¤œå‡ºã¨è¿½è·¡
            results = self.tracker.yolo.track(frame, persist=True)
            
            # æ¤œå‡ºçµæœã‚’å–å¾—
            detections = []
            if results[0].boxes is not None:
                detections.extend(results[0].boxes)
            
            # ObjectTrackerã§è¿½è·¡ã‚’æ›´æ–°
            if detections:
                self.tracker.update_tracking(frame_count, detections)
            
            display_frame = frame.copy()
            boxes_info = []
            
            # ObjectTrackerã®active_tracksã‚’ä½¿ç”¨
            for track_id, bbox in self.tracker.active_tracks.items():
                # ä¿®æ­£ã•ã‚ŒãŸIDãŒã‚ã‚Œã°ãã‚Œã‚’ä½¿ç”¨
                display_id = self.id_corrections.get((frame_count, track_id), track_id)
                
                # å‰Šé™¤ãƒãƒ¼ã‚¯ï¼ˆNoneï¼‰ãŒä»˜ã„ã¦ã„ã‚‹å ´åˆã¯æç”»ã—ãªã„
                if display_id is None:
                    continue
                
                x, y, w, h = bbox
                x1 = x - w/2
                y1 = y - h/2
                x2 = x + w/2
                y2 = y + h/2
                
                boxes_info.append({
                    'yolo_id': track_id,
                    'display_id': display_id,
                    'bbox': (int(x1), int(y1), int(x2), int(y2)),
                    'frame': frame_count
                })
                
                # ãƒœãƒƒã‚¯ã‚¹ã¨IDã‚’æç”»
                # BBoxã‚’ç·‘è‰²ã§è¡¨ç¤ºï¼ˆé¸æŠæ™‚ã¯èµ¤è‰²ï¼‰
                box_color = (0, 0, 255) if self.selected_box == track_id else (0, 255, 0)
                cv2.rectangle(display_frame, (int(x1), int(y1)), (int(x2), int(y2)), box_color, 2)
                # IDã‚’é’è‰²ã§è¡¨ç¤º
                cv2.putText(display_frame, f"{display_id}", 
                          (int(x1), int(y1)-10),
                          cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)
            
            # ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã§è¿½åŠ ã•ã‚ŒãŸç‰©ä½“ã‚’æç”»
            if frame_count in manual_detections:
                for manual_track_id, manual_bbox in manual_detections[frame_count]:
                    x, y, w, h = manual_bbox
                    x1 = int(x - w/2)
                    y1 = int(y - h/2)
                    x2 = int(x + w/2)
                    y2 = int(y + h/2)
                    
                    display_id = manual_track_id
                    boxes_info.append({
                        'yolo_id': manual_track_id,
                        'display_id': display_id,
                        'bbox': (x1, y1, x2, y2),
                        'frame': frame_count
                    })
                    
                    # BBoxã‚’ç·‘è‰²ã§è¡¨ç¤ºï¼ˆé¸æŠæ™‚ã¯èµ¤è‰²ï¼‰
                    box_color = (0, 0, 255) if self.selected_box == manual_track_id else (0, 255, 0)
                    cv2.rectangle(display_frame, (x1, y1), (x2, y2), box_color, 2)
                    # IDã‚’é’è‰²ã§è¡¨ç¤º
                    cv2.putText(display_frame, f"{display_id}", 
                              (x1, y1-10),
                              cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)
            
            # æƒ…å ±è¡¨ç¤º
            cv2.putText(display_frame, f"Frame: {frame_count}", (10, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
            cv2.putText(display_frame, "PAUSED" if self.paused else "PLAYING", (10, 70),
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)
            
            # ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°æ•°ã®è¡¨ç¤º
            total_tracks = len(self.tracker.active_tracks) + (len(manual_detections.get(frame_count, [])) if frame_count in manual_detections else 0)
            cv2.putText(display_frame, f"Tracks: {total_tracks}/{self.max_fish}", (10, 110),
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)
            
            # å‰Šé™¤ã•ã‚ŒãŸIDã®è¡¨ç¤ºï¼ˆå†åˆ©ç”¨å¯èƒ½ï¼‰
            if frame_count in self.deleted_ids_per_frame and len(self.deleted_ids_per_frame[frame_count]) > 0:
                deleted_ids = self.deleted_ids_per_frame[frame_count]
                deleted_str = f"Deleted IDs: {', '.join(map(str, deleted_ids))}"
                cv2.putText(display_frame, deleted_str, (10, 150),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
                y_pos = 185
            else:
                y_pos = 150
            
            if self.selected_box is not None:
                cv2.putText(display_frame, f"Selected: {self.selected_box}", (10, y_pos),
                           cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
            
            cv2.imshow("Ground Truth Generator", display_frame)
            
            # ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒ«ã§è‡ªå‹•åœæ­¢
            if not self.paused and frame_count % review_interval == 0:
                self.paused = True
                print(f"\n--- Frame {frame_count} ã§ãƒ¬ãƒ“ãƒ¥ãƒ¼ ---")
                print(f"æ¤œå‡ºæ•°: {len(boxes_info)}")
            
            # ãƒã‚¦ã‚¹ã‚¯ãƒªãƒƒã‚¯ã§ãƒœãƒƒã‚¯ã‚¹ã‚’é¸æŠ
            if self.mouse_clicked:
                closest_box = None
                min_distance = float('inf')
                
                # æ—¢å­˜ã®ãƒœãƒƒã‚¯ã‚¹ã‚’ãƒã‚§ãƒƒã‚¯
                for track_id, bbox in self.tracker.active_tracks.items():
                    x, y, w, h = bbox
                    x1 = x - w/2
                    y1 = y - h/2
                    x2 = x + w/2
                    y2 = y + h/2
                    
                    if (x1 <= self.mouse_x <= x2) and (y1 <= self.mouse_y <= y2):
                        distance = np.sqrt((self.mouse_x - x)**2 + (self.mouse_y - y)**2)
                        if distance < min_distance:
                            min_distance = distance
                            closest_box = track_id
                
                # ãƒãƒ‹ãƒ¥ã‚¢ãƒ«è¿½åŠ ã•ã‚ŒãŸãƒœãƒƒã‚¯ã‚¹ã‚’ãƒã‚§ãƒƒã‚¯
                if frame_count in manual_detections:
                    for manual_track_id, manual_bbox in manual_detections[frame_count]:
                        x, y, w, h = manual_bbox
                        x1 = x - w/2
                        y1 = y - h/2
                        x2 = x + w/2
                        y2 = y + h/2
                        
                        if (x1 <= self.mouse_x <= x2) and (y1 <= self.mouse_y <= y2):
                            distance = np.sqrt((self.mouse_x - x)**2 + (self.mouse_y - y)**2)
                            if distance < min_distance:
                                min_distance = distance
                                closest_box = manual_track_id
                
                if closest_box is not None:
                    self.selected_box = closest_box
                    print(f"ãƒœãƒƒã‚¯ã‚¹ã‚’é¸æŠ: {closest_box}")
                
                self.mouse_clicked = False
            
            # ã‚­ãƒ¼å…¥åŠ›å‡¦ç†
            key = cv2.waitKey(1 if not self.paused else 0) & 0xFF
            
            if key == ord('q'):
                break
            elif key == ord(' '):
                self.paused = not self.paused
            elif key == ord('s'):
                self._save_ground_truth(temp_detections, output_path)
                print(f"ä¿å­˜ã—ã¾ã—ãŸ: {output_path}")
            elif key == ord('a'):
                # æ–°ã—ã„ç‰©ä½“ã‚’è¿½åŠ ï¼ˆãƒã‚¦ã‚¹ã‚¯ãƒªãƒƒã‚¯ã—ãŸä½ç½®ã¾ãŸã¯æœ€å¾Œã®ã‚¯ãƒªãƒƒã‚¯ä½ç½®ã‚’ä½¿ç”¨ï¼‰
                # ä½ç½®ã‚’æ±ºå®šï¼ˆæœ€å¾Œã®ã‚¯ãƒªãƒƒã‚¯ä½ç½®ã‚’ä½¿ç”¨ã€ãªã‘ã‚Œã°ç”»é¢ä¸­å¤®ï¼‰
                if self.last_mouse_x is not None and self.last_mouse_y is not None:
                    add_x = self.last_mouse_x
                    add_y = self.last_mouse_y
                else:
                    # ç”»é¢ä¸­å¤®ã‚’ä½¿ç”¨
                    add_x = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) / 2) if cap.get(cv2.CAP_PROP_FRAME_WIDTH) > 0 else 320
                    add_y = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) / 2) if cap.get(cv2.CAP_PROP_FRAME_HEIGHT) > 0 else 240
                    print(f"âš ï¸ ãƒã‚¦ã‚¹ã‚¯ãƒªãƒƒã‚¯ä½ç½®ãŒãªã„ãŸã‚ã€ç”»é¢ä¸­å¤® ({add_x}, {add_y}) ã‚’ä½¿ç”¨ã—ã¾ã™")
                
                if frame_count not in manual_detections:
                    manual_detections[frame_count] = []
                
                # ä½¿ç”¨ä¸­ã®IDã‚’å–å¾—
                used_ids = set(self.tracker.active_tracks.keys())
                if frame_count in manual_detections:
                    used_ids.update([t for t, _ in manual_detections[frame_count]])
                
                # å‰Šé™¤ã•ã‚ŒãŸIDã‚’å„ªå…ˆçš„ã«å†åˆ©ç”¨ï¼ˆç¾åœ¨ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã§å‰Šé™¤ã•ã‚ŒãŸIDï¼‰
                new_track_id = None
                if frame_count in self.deleted_ids_per_frame:
                    deleted_ids = self.deleted_ids_per_frame[frame_count]
                    for deleted_id in deleted_ids:
                        if deleted_id not in used_ids and 1 <= deleted_id <= self.max_fish:
                            new_track_id = deleted_id
                            # å†åˆ©ç”¨ã—ãŸIDã‚’å‰Šé™¤ãƒªã‚¹ãƒˆã‹ã‚‰å‰Šé™¤
                            self.deleted_ids_per_frame[frame_count].remove(deleted_id)
                            if not self.deleted_ids_per_frame[frame_count]:
                                del self.deleted_ids_per_frame[frame_count]
                            print(f"â™»ï¸ å‰Šé™¤ã•ã‚ŒãŸID {deleted_id} ã‚’å†åˆ©ç”¨")
                            break
                
                # å‰Šé™¤ã•ã‚ŒãŸIDãŒãªã„å ´åˆã€æœªä½¿ç”¨ã®IDã‚’æ¢ã™
                if new_track_id is None:
                    for candidate_id in range(1, self.max_fish + 1):
                        if candidate_id not in used_ids:
                            new_track_id = candidate_id
                            break
                
                if new_track_id is None:
                    print(f"âŒ æ–°ã—ã„ç‰©ä½“ã‚’è¿½åŠ ã§ãã¾ã›ã‚“: ã™ã¹ã¦ã®ID (1-{self.max_fish}) ãŒä½¿ç”¨ä¸­ã§ã™")
                else:
                    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚µã‚¤ã‚ºã®bboxã‚’ä½œæˆ
                    default_w = 50
                    default_h = 50
                    new_bbox = [add_x, add_y, default_w, default_h]
                    manual_detections[frame_count].append((new_track_id, new_bbox))
                    self.selected_box = new_track_id
                    print(f"âœ“ æ–°ã—ã„ç‰©ä½“ã‚’è¿½åŠ : ID {new_track_id} at ({add_x}, {add_y})")
            elif key == ord('d'):
                # é¸æŠã—ãŸç‰©ä½“ã‚’å‰Šé™¤
                if self.selected_box is not None:
                    deleted_id = self.selected_box
                    
                    # ãƒãƒ‹ãƒ¥ã‚¢ãƒ«è¿½åŠ ã•ã‚ŒãŸç‰©ä½“ã‚’å‰Šé™¤
                    if frame_count in manual_detections:
                        manual_detections[frame_count] = [(t, b) for t, b in manual_detections[frame_count] 
                                                         if t != deleted_id]
                        print(f"âœ“ ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ç‰©ä½“ {deleted_id} ã‚’å‰Šé™¤")
                    
                    # ObjectTrackerã®ãƒˆãƒ©ãƒƒã‚¯ã‚’ä¸€æ™‚çš„ã«ç„¡åŠ¹åŒ–
                    # ç¾åœ¨ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã§ã®ãƒãƒƒãƒãƒ³ã‚°ã‚’ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹ãŸã‚ã«
                    # id_correctionsã‚’ä½¿ã£ã¦å‰Šé™¤ãƒãƒ¼ã‚¯ã‚’ä»˜ã‘ã‚‹
                    self.id_corrections[(frame_count, deleted_id)] = None  # Noneã¯å‰Šé™¤ã‚’æ„å‘³ã™ã‚‹
                    
                    # å‰Šé™¤ã•ã‚ŒãŸIDã‚’è¨˜éŒ²ï¼ˆå†åˆ©ç”¨ç”¨ï¼‰
                    if frame_count not in self.deleted_ids_per_frame:
                        self.deleted_ids_per_frame[frame_count] = []
                    if deleted_id not in self.deleted_ids_per_frame[frame_count]:
                        self.deleted_ids_per_frame[frame_count].append(deleted_id)
                        print(f"âœ“ å‰Šé™¤ã•ã‚ŒãŸID {deleted_id} ã‚’è¨˜éŒ²ï¼ˆå†åˆ©ç”¨å¯èƒ½ï¼‰")
                    
                    print(f"âœ“ ãƒˆãƒ©ãƒƒã‚¯ {deleted_id} ã‚’ãƒ•ãƒ¬ãƒ¼ãƒ  {frame_count} ã‹ã‚‰å‰Šé™¤")
                    
                    self.selected_box = None
                else:
                    print("âš ï¸ å‰Šé™¤ã™ã‚‹ç‰©ä½“ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“")
            elif key == ord('n') or key == 83:  # å³çŸ¢å°
                # æ¬¡ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã¸ï¼ˆãŸã ã—å‹•ç”»ã®ç·ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ã‚’è¶…ãˆãªã„ï¼‰
                if frame_count < total_frames:
                    frame_count += 1
                    self.paused = True
                    print(f"ãƒ•ãƒ¬ãƒ¼ãƒ  {frame_count} ã«ç§»å‹•")
                else:
                    print(f"ãƒ•ãƒ¬ãƒ¼ãƒ  {frame_count} ã¯æœ€å¾Œã®ãƒ•ãƒ¬ãƒ¼ãƒ ã§ã™")
            elif key == ord('p') or key == 81:  # å·¦çŸ¢å°
                # å‰ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã¸ï¼ˆãŸã ã—1æœªæº€ã«ãªã‚‰ãªã„ï¼‰
                if frame_count > 1:
                    frame_count -= 1
                    self.paused = True
                    print(f"ãƒ•ãƒ¬ãƒ¼ãƒ  {frame_count} ã«ç§»å‹•")
                else:
                    print(f"ãƒ•ãƒ¬ãƒ¼ãƒ  {frame_count} ã¯æœ€åˆã®ãƒ•ãƒ¬ãƒ¼ãƒ ã§ã™")
            elif ord('0') <= key <= ord('9'):
                # æ•°å­—ã‚­ãƒ¼ã§IDã‚’å¤‰æ›´
                new_id = key - ord('0')
                
                # 0ã‚­ãƒ¼ãŒæŠ¼ã•ã‚ŒãŸå ´åˆã€max_fishãŒ10ã®å ´åˆã¯10ã¨ã—ã¦æ‰±ã†
                if new_id == 0 and self.max_fish == 10:
                    new_id = 10
                
                # IDã®ç¯„å›²ãƒã‚§ãƒƒã‚¯ï¼ˆ1ã€œmax_fishã®ç¯„å›²å†…ï¼‰
                if new_id < 1 or new_id > self.max_fish:
                    print(f"âš ï¸ ç„¡åŠ¹ãªID: {new_id}ã€‚IDã¯1-{self.max_fish}ã®ç¯„å›²ã§æŒ‡å®šã—ã¦ãã ã•ã„")
                elif self.selected_box is not None:
                    if frame_count in manual_detections:
                        # ãƒãƒ‹ãƒ¥ã‚¢ãƒ«è¿½åŠ ã•ã‚ŒãŸç‰©ä½“ã®å ´åˆ
                        for i, (track_id, bbox) in enumerate(manual_detections[frame_count]):
                            if track_id == self.selected_box:
                                manual_detections[frame_count][i] = (new_id, bbox)
                                print(f"âœ“ ID {self.selected_box} ã‚’ {new_id} ã«å¤‰æ›´")
                                self.selected_box = new_id
                                break
                    else:
                        # ObjectTrackerã®ç‰©ä½“ã®å ´åˆ
                        self.id_corrections[(frame_count, self.selected_box)] = new_id
                        print(f"âœ“ ID {self.selected_box} ã‚’ {new_id} ã«å¤‰æ›´")
            
            # æ¤œå‡ºçµæœã‚’ä¸€æ™‚ä¿å­˜
            temp_detections.append({
                'frame': frame_count,
                'boxes': boxes_info
            })
        
        cap.release()
        cv2.destroyAllWindows()
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ ç¯„å›²ã®ç¢ºèªï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
        if temp_detections:
            frames_recorded = set(d['frame'] for d in temp_detections)
            min_frame = min(frames_recorded)
            max_frame = max(frames_recorded)
            print(f"\nğŸ“Š Ground Truthçµ±è¨ˆ:")
            print(f"   è¨˜éŒ²ã•ã‚ŒãŸãƒ•ãƒ¬ãƒ¼ãƒ ç¯„å›²: {min_frame} - {max_frame}")
            print(f"   è¨˜éŒ²ã•ã‚ŒãŸç·ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {len(frames_recorded)}")
            print(f"   å‹•ç”»ã®ç·ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {total_frames}")
            print(f"   æœ€çµ‚frame_count: {frame_count}")
            
            if max_frame != total_frames:
                print(f"   âš ï¸ è­¦å‘Š: æœ€å¾Œã®ãƒ•ãƒ¬ãƒ¼ãƒ ({total_frames})ãŒè¨˜éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“")
                print(f"   è¨˜éŒ²ã•ã‚ŒãŸæœ€å¤§ãƒ•ãƒ¬ãƒ¼ãƒ : {max_frame}")
            
            # ãƒ•ãƒ¬ãƒ¼ãƒ 1ãŒè¨˜éŒ²ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
            if 1 not in frames_recorded:
                print(f"   âš ï¸ è­¦å‘Š: æœ€åˆã®ãƒ•ãƒ¬ãƒ¼ãƒ (1)ãŒè¨˜éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            
            # é€£ç¶šã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãŒæ¬ ã‘ã¦ã„ã‚‹ã‹ç¢ºèª
            missing_frames = []
            for f in range(1, total_frames + 1):
                if f not in frames_recorded:
                    missing_frames.append(f)
            
            if missing_frames:
                print(f"   âš ï¸ è­¦å‘Š: {len(missing_frames)}ãƒ•ãƒ¬ãƒ¼ãƒ ãŒæ¬ ã‘ã¦ã„ã¾ã™")
                if len(missing_frames) <= 10:
                    print(f"   æ¬ ã‘ã¦ã„ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ : {missing_frames}")
                else:
                    print(f"   æ¬ ã‘ã¦ã„ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ï¼ˆæœ€åˆã®10å€‹ï¼‰: {missing_frames[:10]}...")
        
        # æœ€çµ‚ä¿å­˜
        self._save_ground_truth(temp_detections, output_path)
        print(f"\nGround Truthç”Ÿæˆå®Œäº†: {output_path}")
        return output_path
    
    # def method2_full_automatic(self, video_path, output_path, confidence_threshold=0.5):
    #     """
    #     æ–¹æ³•2: å®Œå…¨è‡ªå‹•ç”Ÿæˆï¼ˆæ¯”è¼ƒç”¨ï¼‰
        
    #     ObjectTrackerã®çµæœã‚’ãã®ã¾ã¾Ground Truthã¨ã—ã¦ä¿å­˜
    #     ç•°ãªã‚‹è¨­å®šã§å‹•ã‹ã—ãŸæ™‚ã®æ¯”è¼ƒåŸºæº–ã¨ã—ã¦ä½¿ç”¨
        
    #     Args:
    #         video_path: å…¥åŠ›å‹•ç”»
    #         output_path: Ground Truthä¿å­˜å…ˆ
    #         confidence_threshold: ä¿¡é ¼åº¦é–¾å€¤
    #     """
    #     print("\n=== æ–¹æ³•2: å®Œå…¨è‡ªå‹•Ground Truthç”Ÿæˆï¼ˆObjectTrackerä½¿ç”¨ï¼‰===")
    #     print(f"æœ€å¤§ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°æ•°: {self.max_fish} (IDã¯1-{self.max_fish}ã§å‰²ã‚Šå½“ã¦)")
    #     print("ObjectTrackerã®çµæœã‚’ãã®ã¾ã¾ä¿å­˜ã—ã¾ã™...")
        
    #     cap = cv2.VideoCapture(video_path)
    #     # object_tracking.pyã¨åŒã˜ãƒ•ãƒ¬ãƒ¼ãƒ ã‚«ã‚¦ãƒ³ãƒˆæ–¹å¼ï¼ˆãƒ•ãƒ¬ãƒ¼ãƒ 1ã‹ã‚‰å§‹ã¾ã‚‹ï¼‰
    #     frame_count = 0  # åˆæœŸåŒ–ã¯0ï¼ˆobject_tracking.pyã¨åŒã˜ï¼‰
    #     all_detections = []
        
    #     # å‹•ç”»ã®ç·ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ã‚’å–å¾—ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
    #     total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    #     print(f"å‹•ç”»ã®ç·ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {total_frames}")
        
    #     while cap.isOpened():
    #         # object_tracking.pyã¨åŒã˜æ–¹å¼ï¼šãƒ•ãƒ¬ãƒ¼ãƒ ã‚’èª­ã¿è¾¼ã‚€
    #         ret, frame = cap.read()
    #         if not ret:
    #             break
            
    #         frame_count += 1  # object_tracking.pyã¨åŒã˜ï¼šèª­ã¿è¾¼ã¿å¾Œã«ã‚«ã‚¦ãƒ³ãƒˆ
            
    #         # YOLOã§æ¤œå‡º
    #         results = self.tracker.yolo.track(frame, persist=True)
            
    #         # æ¤œå‡ºçµæœã‚’å–å¾—
    #         detections = []
    #         if results[0].boxes is not None:
    #             detections.extend(results[0].boxes)
            
    #         # ObjectTrackerã§è¿½è·¡ã‚’æ›´æ–°
    #         if detections:
    #             self.tracker.update_tracking(frame_count, detections)
            
    #         # ObjectTrackerã®active_tracksã‚’ä½¿ç”¨
    #         for track_id, bbox in self.tracker.active_tracks.items():
    #             x, y, w, h = bbox
                
    #             # MOTChallengeå½¢å¼ (bboxã¯ä¸­å¿ƒåº§æ¨™ãªã®ã§ã€å·¦ä¸Šè§’ã«å¤‰æ›)
    #             all_detections.append({
    #                 'frame': frame_count,
    #                 'id': track_id,
    #                 'x': x - w/2,
    #                 'y': y - h/2,
    #                 'w': w,
    #                 'h': h,
    #                 'conf': 1.0  # ObjectTrackerã¯ä¿¡é ¼åº¦ã‚’ä¿æŒã—ã¦ã„ãªã„ã®ã§1.0
    #             })
            
    #         if frame_count % 100 == 0:
    #             print(f"å‡¦ç†æ¸ˆã¿: {frame_count} ãƒ•ãƒ¬ãƒ¼ãƒ ã€ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒˆãƒ©ãƒƒã‚¯: {len(self.tracker.active_tracks)}")
        
    #     cap.release()
        
    #     # MOTChallengeå½¢å¼ã§ä¿å­˜
    #     self._save_mot_format(all_detections, output_path)
    #     print(f"å®Œäº†: {len(all_detections)} æ¤œå‡ºã‚’ä¿å­˜")
    #     return output_path
    
    # def method3_sampling(self, video_path, output_dir, sample_interval=30):
    #     """
    #     æ–¹æ³•3: ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ç”Ÿæˆï¼ˆé•·æ™‚é–“å‹•ç”»ç”¨ï¼‰
        
    #     Nç§’ã”ã¨ã«ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æŠ½å‡ºã—ã€ç”»åƒã¨ã—ã¦ä¿å­˜
    #     CVAT/LabelImgãªã©ã®å¤–éƒ¨ãƒ„ãƒ¼ãƒ«ã§æ‰‹å‹•ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
        
    #     Args:
    #         video_path: å…¥åŠ›å‹•ç”»
    #         output_dir: ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã®ä¿å­˜å…ˆ
    #         sample_interval: ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°é–“éš”ï¼ˆãƒ•ãƒ¬ãƒ¼ãƒ æ•°ï¼‰
    #     """
    #     print("\n=== æ–¹æ³•3: ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°Ground Truthç”Ÿæˆ ===")
    #     print(f"{sample_interval}ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã«ç”»åƒã‚’æŠ½å‡ºã—ã¾ã™")
    #     print("ã“ã‚Œã‚‰ã®ç”»åƒã‚’CVATãªã©ã§ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã—ã¦ãã ã•ã„")
        
    #     os.makedirs(output_dir, exist_ok=True)
        
    #     cap = cv2.VideoCapture(video_path)
    #     frame_count = 0
    #     saved_count = 0
        
    #     fps = cap.get(cv2.CAP_PROP_FPS)
        
    #     while cap.isOpened():
    #         ret, frame = cap.read()
    #         if not ret:
    #             break
            
    #         frame_count += 1
            
    #         if frame_count % sample_interval == 0:
    #             # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä¿å­˜
    #             output_path = os.path.join(output_dir, f"frame_{frame_count:06d}.jpg")
    #             cv2.imwrite(output_path, frame)
    #             saved_count += 1
                
    #             # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚‚ä¿å­˜
    #             metadata_path = os.path.join(output_dir, f"frame_{frame_count:06d}.json")
    #             with open(metadata_path, 'w') as f:
    #                 json.dump({
    #                     'frame_number': frame_count,
    #                     'timestamp': frame_count / fps,
    #                     'video_path': video_path
    #                 }, f, indent=2)
                
    #             print(f"ä¿å­˜: {output_path}")
        
    #     cap.release()
        
    #     print(f"\nå®Œäº†: {saved_count} ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä¿å­˜")
    #     print(f"ä¿å­˜å…ˆ: {output_dir}")
    #     print("\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    #     print("1. CVATã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«: pip install cvat-cli")
    #     print("2. ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    #     print("3. ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ä½œæ¥­")
    #     print("4. MOTChallengeå½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
        
    #     return output_dir
    
    def _save_ground_truth(self, detections, output_path):
        """æ¤œå‡ºçµæœã‚’MOTChallengeå½¢å¼ã§ä¿å­˜"""
        all_data = []
        for frame_data in detections:
            frame_num = frame_data['frame']
            for box_info in frame_data.get('boxes', []):
                x1, y1, x2, y2 = box_info['bbox']
                obj_id = self.id_corrections.get(
                    (frame_num, box_info['yolo_id']), 
                    box_info['display_id']
                )
                
                # å‰Šé™¤ãƒãƒ¼ã‚¯ï¼ˆNoneï¼‰ãŒä»˜ã„ã¦ã„ã‚‹å ´åˆã¯ä¿å­˜ã—ãªã„
                if obj_id is None:
                    continue
                
                all_data.append({
                    'frame': frame_num,
                    'id': obj_id,
                    'x': x1,
                    'y': y1,
                    'w': x2 - x1,
                    'h': y2 - y1,
                    'conf': 1.0
                })
        
        self._save_mot_format(all_data, output_path)
    
    def _save_mot_format(self, detections, output_path):
        """MOTChallengeå½¢å¼ã§ä¿å­˜"""
        with open(output_path, 'w') as f:
            for det in sorted(detections, key=lambda x: (x['frame'], x['id'])):
                # MOTChallengeå½¢å¼: frame, id, x, y, w, h, conf, -1, -1, -1
                f.write(f"{det['frame']},{det['id']},{det['x']:.2f},{det['y']:.2f},"
                       f"{det['w']:.2f},{det['h']:.2f},{det.get('conf', 1.0):.2f},-1,-1,-1\n")


# ä½¿ç”¨ä¾‹
if __name__ == "__main__":
    # æœ€å¤§ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°æ•°ã‚’è¨­å®šï¼ˆobject_tracking.pyã¨åŒã˜ï¼‰
    MAX_FISH = 10  # ã“ã®å€¤ã‚’å¤‰æ›´ã™ã‚‹ã“ã¨ã§æœ€å¤§ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°æ•°ã‚’èª¿æ•´ã§ãã¾ã™
    
    model_path = "/Users/rin/Documents/ç•¢æ¥­å°ˆé¡Œ/yolo_detect_zebrafish/train_results/weights/best.pt"
    
    # GroundTruthGeneratorã‚’åˆæœŸåŒ–ï¼ˆmax_fishã‚’æŒ‡å®šï¼‰
    generator = GroundTruthGenerator(
        model_path=model_path,
        max_fish=MAX_FISH
    )
    
    video_path = "/Users/rin/Documents/ç•¢æ¥­å°ˆé¡Œ/YOLO/video/test/9min_3D_left.mp4"
    
    # ========================================
    # ä½¿ç”¨ä¾‹1: åŠè‡ªå‹•ç”Ÿæˆï¼ˆæ¨å¥¨ï¼‰
    # ========================================
    print("\nã€æ¨å¥¨ã€‘æ–¹æ³•1: åŠè‡ªå‹•ç”Ÿæˆ")
    print("ãƒˆãƒ©ãƒƒã‚«ãƒ¼ãŒäºˆæ¸¬ â†’ ã‚ãªãŸãŒç¢ºèªãƒ»ä¿®æ­£")
    print(f"æœ€å¤§ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°æ•°: {MAX_FISH} (IDs: 1-{MAX_FISH})")
    
    gt_path = generator.method1_semi_automatic(
        video_path=video_path,
        output_path="/Users/rin/Documents/ç•¢æ¥­å°ˆé¡Œ/yolo_detect_zebrafish/evaluate_mot_system/ground_truth/semi_auto.txt",
        review_interval=30  # 30ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã«ç¢ºèª
    )
    
    # # ========================================
    # # ä½¿ç”¨ä¾‹2: å®Œå…¨è‡ªå‹•ç”Ÿæˆï¼ˆæ¯”è¼ƒç”¨ï¼‰
    # # ========================================
    # print("\næ–¹æ³•2: å®Œå…¨è‡ªå‹•ç”Ÿæˆï¼ˆåˆ¥ã®è¨­å®šã¨ã®æ¯”è¼ƒç”¨ï¼‰")
    
    # baseline_gt = generator.method2_full_automatic(
    #     video_path=video_path,
    #     output_path="/Users/rin/Documents/ç•¢æ¥­å°ˆé¡Œ/yolo_detect_zebrafish/evaluate_mot_system/ground_truth/baseline.txt",
    #     confidence_threshold=0.5
    # )
    
    # # ========================================
    # # ä½¿ç”¨ä¾‹3: ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆé•·æ™‚é–“å‹•ç”»ç”¨ï¼‰
    # # ========================================
    # print("\næ–¹æ³•3: ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ç”Ÿæˆï¼ˆé•·æ™‚é–“å‹•ç”»å‘ã‘ï¼‰")
    
    # sample_dir = generator.method3_sampling(
    #     video_path=video_path,
    #     output_dir="/Users/rin/Documents/ç•¢æ¥­å°ˆé¡Œ/yolo_detect_zebrafish/evaluate_mot_system/ground_truth/samples",
    #     sample_interval=30  # 30ãƒ•ãƒ¬ãƒ¼ãƒ  = 1ç§’ã”ã¨ï¼ˆ30fpsæƒ³å®šï¼‰
    # )