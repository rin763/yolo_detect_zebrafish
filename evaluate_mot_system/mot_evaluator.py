"""
MOT (Multiple Object Tracking) è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ 
MOTA, MOTP, IDF1ãªã©ã®æ¨™æº–æŒ‡æ¨™ã‚’è¨ˆç®—

ä½¿ã„æ–¹:
    from mot_evaluator import MOTEvaluator
    
    evaluator = MOTEvaluator()
    
    # ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã«è©•ä¾¡ã‚’æ›´æ–°
    evaluator.update_frame(ground_truth, predictions)
    
    # æœ€çµ‚çµæœã‚’è¡¨ç¤º
    evaluator.print_summary()
"""

import numpy as np
from collections import defaultdict
import json

class MOTEvaluator:
    """
    Multiple Object Tracking (MOT) è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ 
    ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§è©•ä¾¡æŒ‡æ¨™ã‚’è¨ˆç®—ã—ã€ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ã«ãƒ‡ãƒ¼ã‚¿ã‚’ç®¡ç†
    """
    
    def __init__(self, iou_threshold=0.5, distance_threshold=50):
        """
        Args:
            iou_threshold: IoUãƒãƒƒãƒãƒ³ã‚°ã®é–¾å€¤
            distance_threshold: è·é›¢ãƒ™ãƒ¼ã‚¹ãƒãƒƒãƒãƒ³ã‚°ã®é–¾å€¤ï¼ˆãƒ”ã‚¯ã‚»ãƒ«ï¼‰
        """
        self.iou_threshold = iou_threshold
        self.distance_threshold = distance_threshold
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã®è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¨ˆç®—ç”¨ï¼‰
        self.frame_metrics = {
            'true_positives': 0,      # æ­£ã—ãæ¤œå‡ºãƒ»è¿½è·¡ã§ããŸæ•°
            'false_positives': 0,     # èª¤æ¤œå‡ºæ•°
            'false_negatives': 0,     # è¦‹é€ƒã—æ•°
            'id_switches': 0,         # IDåˆ‡ã‚Šæ›¿ã‚ã‚Šå›æ•°
            'fragmentations': 0,      # ãƒˆãƒ©ãƒƒã‚¯æ–­ç‰‡åŒ–å›æ•°
            'total_distance_error': 0.0,  # ç·è·é›¢èª¤å·®
            'matched_count': 0,       # ãƒãƒƒãƒãƒ³ã‚°æˆåŠŸæ•°
        }
        
        # IDç®¡ç†ç”¨
        self.prev_frame_matches = {}  # {gt_id: pred_id}
        self.track_status = {}  # {gt_id: {'active': bool, 'last_matched_frame': int}}
        
        # ãƒˆãƒ©ãƒƒã‚¯ãƒ¬ãƒ™ãƒ«ã®çµ±è¨ˆï¼ˆãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ï¼‰
        self.track_lengths = defaultdict(int)  # {pred_id: length}
        self.track_gt_matches = defaultdict(set)  # {pred_id: set of gt_ids}
        
        # ç¾åœ¨ã®ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·
        self.current_frame = 0
        
        # è»½é‡ãªä½ç½®å±¥æ­´ï¼ˆæœ€æ–°Nå€‹ã®ã¿ä¿æŒï¼‰
        self.position_history_size = 100
        self.recent_positions = defaultdict(lambda: defaultdict(list))  # {frame: {id: position}}
        
    def compute_iou(self, box1, box2):
        """
        IoU (Intersection over Union) ã‚’è¨ˆç®—
        boxå½¢å¼: [x_center, y_center, width, height]
        """
        # ä¸­å¿ƒåº§æ¨™å½¢å¼ã‹ã‚‰ã‚³ãƒ¼ãƒŠãƒ¼åº§æ¨™å½¢å¼ã«å¤‰æ›
        x1_min = box1[0] - box1[2] / 2
        y1_min = box1[1] - box1[3] / 2
        x1_max = box1[0] + box1[2] / 2
        y1_max = box1[1] + box1[3] / 2
        
        x2_min = box2[0] - box2[2] / 2
        y2_min = box2[1] - box2[3] / 2
        x2_max = box2[0] + box2[2] / 2
        y2_max = box2[1] + box2[3] / 2
        
        # äº¤å·®é ˜åŸŸã‚’è¨ˆç®—
        inter_xmin = max(x1_min, x2_min)
        inter_ymin = max(y1_min, y2_min)
        inter_xmax = min(x1_max, x2_max)
        inter_ymax = min(y1_max, y2_max)
        
        inter_area = max(0, inter_xmax - inter_xmin) * max(0, inter_ymax - inter_ymin)
        
        # å„ãƒœãƒƒã‚¯ã‚¹ã®é¢ç©
        box1_area = box1[2] * box1[3]
        box2_area = box2[2] * box2[3]
        
        # Unioné¢ç©
        union_area = box1_area + box2_area - inter_area
        
        if union_area == 0:
            return 0.0
        
        return inter_area / union_area
    
    def compute_center_distance(self, box1, box2):
        """ä¸­å¿ƒç‚¹é–“ã®è·é›¢ã‚’è¨ˆç®—"""
        return np.sqrt((box1[0] - box2[0])**2 + (box1[1] - box2[1])**2)
    
    def match_detections(self, ground_truth, predictions):
        """
        Ground Truthã¨Predictionã‚’ãƒãƒƒãƒãƒ³ã‚°ï¼ˆãƒãƒ³ã‚¬ãƒªã‚¢ãƒ³ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ çš„ï¼‰
        
        Args:
            ground_truth: {gt_id: [x, y, w, h], ...}
            predictions: {pred_id: [x, y, w, h], ...}
        
        Returns:
            matches: {gt_id: pred_id}
            unmatched_gt: set of gt_ids
            unmatched_pred: set of pred_ids
        """
        if not ground_truth or not predictions:
            return {}, set(ground_truth.keys()), set(predictions.keys())
        
        # ã‚³ã‚¹ãƒˆãƒãƒˆãƒªãƒƒã‚¯ã‚¹ã‚’æ§‹ç¯‰ï¼ˆIoUãƒ™ãƒ¼ã‚¹ï¼‰
        gt_ids = list(ground_truth.keys())
        pred_ids = list(predictions.keys())
        
        cost_matrix = np.zeros((len(gt_ids), len(pred_ids)))
        
        for i, gt_id in enumerate(gt_ids):
            for j, pred_id in enumerate(pred_ids):
                iou = self.compute_iou(ground_truth[gt_id], predictions[pred_id])
                # IoUãŒé–¾å€¤ä»¥ä¸Šãªã‚‰ã‚³ã‚¹ãƒˆã¯ (1 - IoU)ã€æœªæº€ãªã‚‰ç„¡é™å¤§
                if iou >= self.iou_threshold:
                    cost_matrix[i, j] = 1 - iou
                else:
                    cost_matrix[i, j] = np.inf
        
        # ç°¡æ˜“çš„ãªã‚°ãƒªãƒ¼ãƒ‡ã‚£ãƒãƒƒãƒãƒ³ã‚°ï¼ˆæœ¬æ ¼å®Ÿè£…ã§ã¯linear_sum_assignmentä½¿ç”¨æ¨å¥¨ï¼‰
        matches = {}
        unmatched_gt = set(gt_ids)
        unmatched_pred = set(pred_ids)
        
        while True:
            # æœ€å°ã‚³ã‚¹ãƒˆã‚’æ¢ã™
            if np.all(np.isinf(cost_matrix)):
                break
            
            min_idx = np.unravel_index(np.argmin(cost_matrix), cost_matrix.shape)
            i, j = min_idx
            
            if cost_matrix[i, j] == np.inf:
                break
            
            gt_id = gt_ids[i]
            pred_id = pred_ids[j]
            
            matches[gt_id] = pred_id
            unmatched_gt.discard(gt_id)
            unmatched_pred.discard(pred_id)
            
            # ãƒãƒƒãƒã—ãŸè¡Œã¨åˆ—ã‚’ç„¡åŠ¹åŒ–
            cost_matrix[i, :] = np.inf
            cost_matrix[:, j] = np.inf
        
        return matches, unmatched_gt, unmatched_pred
    
    def update_frame(self, ground_truth, predictions):
        """
        1ãƒ•ãƒ¬ãƒ¼ãƒ åˆ†ã®è©•ä¾¡ã‚’æ›´æ–°
        
        Args:
            ground_truth: {gt_id: [x, y, w, h], ...}
            predictions: {pred_id: [x, y, w, h], ...}
        """
        self.current_frame += 1
        
        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ï¼ˆæœ€åˆã®æ•°ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã¿è¡¨ç¤ºï¼‰
        if self.current_frame <= 3:
            print(f"\nğŸ” Debug Frame {self.current_frame}:")
            print(f"   GT objects: {len(ground_truth)} - IDs: {list(ground_truth.keys())[:5]}")
            print(f"   Predictions: {len(predictions)} - IDs: {list(predictions.keys())[:5]}")
            if ground_truth:
                gt_sample_id = list(ground_truth.keys())[0]
                print(f"   Sample GT bbox: ID {gt_sample_id} = {ground_truth[gt_sample_id]}")
            if predictions:
                pred_sample_id = list(predictions.keys())[0]
                print(f"   Sample Pred bbox: ID {pred_sample_id} = {predictions[pred_sample_id]}")
        
        # ãƒãƒƒãƒãƒ³ã‚°ã‚’å®Ÿè¡Œ
        matches, unmatched_gt, unmatched_pred = self.match_detections(
            ground_truth, predictions
        )
        
        # ãƒãƒƒãƒãƒ³ã‚°çµæœã‚’ãƒ‡ãƒãƒƒã‚°ï¼ˆæœ€åˆã®æ•°ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã¿ï¼‰
        if self.current_frame <= 3:
            print(f"   Matches: {len(matches)}")
            if matches:
                print(f"   Sample matches: {list(matches.items())[:3]}")
            print(f"   Unmatched GT: {len(unmatched_gt)}, Unmatched Pred: {len(unmatched_pred)}")
            print(f"   IoU threshold: {self.iou_threshold}, Distance threshold: {self.distance_threshold}")
        
        # ãƒãƒƒãƒãƒ³ã‚°ãŒ0ã®å ´åˆã®è­¦å‘Š
        if len(matches) == 0 and len(ground_truth) > 0 and len(predictions) > 0:
            if self.current_frame % 100 == 1:  # 100ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã«1å›ã ã‘è¡¨ç¤º
                print(f"âš ï¸ Frame {self.current_frame}: No matches! GT={len(ground_truth)}, Pred={len(predictions)}")
                print(f"   This may cause IDF1=0. Check IoU threshold ({self.iou_threshold}) or distance threshold ({self.distance_threshold})")
        
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’æ›´æ–°
        self.frame_metrics['true_positives'] += len(matches)
        self.frame_metrics['false_positives'] += len(unmatched_pred)
        self.frame_metrics['false_negatives'] += len(unmatched_gt)
        self.frame_metrics['matched_count'] += len(matches)
        
        # è·é›¢èª¤å·®ã‚’è¨ˆç®—
        for gt_id, pred_id in matches.items():
            distance = self.compute_center_distance(
                ground_truth[gt_id], predictions[pred_id]
            )
            self.frame_metrics['total_distance_error'] += distance
        
        # IDåˆ‡ã‚Šæ›¿ã‚ã‚Šã¨ãƒ•ãƒ©ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ¤œå‡º
        for gt_id, pred_id in matches.items():
            # å‰ãƒ•ãƒ¬ãƒ¼ãƒ ã§ã“ã®GT IDãŒç•°ãªã‚‹Pred IDã«ãƒãƒƒãƒã—ã¦ã„ãŸå ´åˆ
            if gt_id in self.prev_frame_matches:
                if self.prev_frame_matches[gt_id] != pred_id:
                    self.frame_metrics['id_switches'] += 1
                    print(f"Frame {self.current_frame}: ID switch detected for GT {gt_id}: {self.prev_frame_matches[gt_id]} -> {pred_id}")
            
            # ãƒˆãƒ©ãƒƒã‚¯ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’æ›´æ–°
            if gt_id in self.track_status:
                if not self.track_status[gt_id]['active']:
                    # ä¸€åº¦é€”åˆ‡ã‚ŒãŸãƒˆãƒ©ãƒƒã‚¯ãŒå†é–‹ = ãƒ•ãƒ©ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
                    self.frame_metrics['fragmentations'] += 1
                    print(f"Frame {self.current_frame}: Fragmentation detected for GT {gt_id}")
            
            self.track_status[gt_id] = {
                'active': True,
                'last_matched_frame': self.current_frame
            }
            
            # ãƒˆãƒ©ãƒƒã‚¯çµ±è¨ˆã‚’æ›´æ–°
            self.track_lengths[pred_id] += 1
            self.track_gt_matches[pred_id].add(gt_id)
        
        # è¦‹é€ƒã•ã‚ŒãŸGT IDã¯ãƒˆãƒ©ãƒƒã‚¯ãŒé€”åˆ‡ã‚ŒãŸ
        for gt_id in unmatched_gt:
            if gt_id in self.track_status:
                self.track_status[gt_id]['active'] = False
        
        # æ¬¡ãƒ•ãƒ¬ãƒ¼ãƒ ã®ãŸã‚ã«ç¾åœ¨ã®ãƒãƒƒãƒãƒ³ã‚°ã‚’ä¿å­˜
        self.prev_frame_matches = matches.copy()
        
        # è»½é‡ãªä½ç½®å±¥æ­´ã‚’æ›´æ–°ï¼ˆæœ€æ–°100ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã¿ï¼‰
        self.recent_positions[self.current_frame] = {
            'gt': ground_truth.copy(),
            'pred': predictions.copy()
        }
        
        # å¤ã„ä½ç½®å±¥æ­´ã‚’å‰Šé™¤
        old_frames = [f for f in self.recent_positions.keys() 
                      if f < self.current_frame - self.position_history_size]
        for frame in old_frames:
            del self.recent_positions[frame]
    
    def calculate_mota(self):
        """MOTA (Multiple Object Tracking Accuracy) ã‚’è¨ˆç®—"""
        total_gt = (self.frame_metrics['true_positives'] + 
                   self.frame_metrics['false_negatives'])
        
        if total_gt == 0:
            return 0.0
        
        mota = 1 - (
            (self.frame_metrics['false_negatives'] + 
             self.frame_metrics['false_positives'] + 
             self.frame_metrics['id_switches']) / total_gt
        )
        
        return mota
    
    def calculate_motp(self):
        """MOTP (Multiple Object Tracking Precision) ã‚’è¨ˆç®—"""
        if self.frame_metrics['matched_count'] == 0:
            return 0.0
        
        motp = self.frame_metrics['total_distance_error'] / self.frame_metrics['matched_count']
        return motp
    
    def calculate_idf1(self):
        """
        IDF1 (ID F1 Score) ã‚’è¨ˆç®—
        ç°¡æ˜“ç‰ˆ: å„äºˆæ¸¬ãƒˆãƒ©ãƒƒã‚¯ãŒä¸»ã«ãƒãƒƒãƒã™ã‚‹GT IDã¨ã®ä¸€è‡´åº¦
        """
        total_idtp = 0  # ID True Positives
        total_idfp = 0  # ID False Positives
        total_idfn = 0  # ID False Negatives
        
        # ãƒ‡ãƒãƒƒã‚°: track_gt_matchesã®çŠ¶æ…‹ã‚’ç¢ºèª
        if len(self.track_gt_matches) == 0:
            print("\nâš ï¸ IDF1 Calculation Debug:")
            print(f"   track_gt_matches is EMPTY!")
            print(f"   track_lengths: {len(self.track_lengths)} tracks")
            print(f"   This means no GT-Pred matches were recorded.")
            print(f"   Check if update_frame() is being called with valid data.")
        
        for pred_id, gt_ids in self.track_gt_matches.items():
            if len(gt_ids) == 0:
                continue
            
            # ã“ã®ãƒˆãƒ©ãƒƒã‚¯ãŒæœ€ã‚‚å¤šããƒãƒƒãƒã—ãŸGT ID
            # ç°¡æ˜“ç‰ˆã§ã¯ã€1ã¤ã®GT IDã«æœ€ã‚‚ãƒãƒƒãƒã—ãŸå ´åˆã‚’IDTPã¨ã™ã‚‹
            if len(gt_ids) == 1:
                total_idtp += self.track_lengths[pred_id]
            else:
                # è¤‡æ•°ã®GT IDã«ãƒãƒƒãƒ = IDåˆ‡ã‚Šæ›¿ã‚ã‚ŠãŒã‚ã£ãŸ
                total_idfp += self.track_lengths[pred_id]
        
        # è¦‹é€ƒã•ã‚ŒãŸãƒ•ãƒ¬ãƒ¼ãƒ 
        total_idfn = self.frame_metrics['false_negatives']
        
        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤º
        print(f"\nğŸ“Š IDF1 Calculation:")
        print(f"   IDTP (ID True Positives): {total_idtp}")
        print(f"   IDFP (ID False Positives): {total_idfp}")
        print(f"   IDFN (ID False Negatives): {total_idfn}")
        print(f"   Unique Pred Tracks: {len(self.track_gt_matches)}")
        print(f"   Total Track Lengths: {sum(self.track_lengths.values())}")
        
        if (total_idtp + total_idfp) == 0 or (total_idtp + total_idfn) == 0:
            print(f"   âš ï¸ IDF1 = 0 because denominator is 0")
            if (total_idtp + total_idfp) == 0:
                print(f"      No ID matches found (IDTP + IDFP = 0)")
            if (total_idtp + total_idfn) == 0:
                print(f"      No GT objects (IDTP + IDFN = 0)")
            return 0.0
        
        precision = total_idtp / (total_idtp + total_idfp)
        recall = total_idtp / (total_idtp + total_idfn)
        
        print(f"   ID Precision: {precision:.4f}")
        print(f"   ID Recall: {recall:.4f}")
        
        if precision + recall == 0:
            print(f"   âš ï¸ IDF1 = 0 because precision + recall = 0")
            return 0.0
        
        idf1 = 2 * precision * recall / (precision + recall)
        print(f"   IDF1: {idf1:.4f}")
        return idf1
    
    def get_summary(self):
        """è©•ä¾¡ã‚µãƒãƒªãƒ¼ã‚’å–å¾—"""
        mota = self.calculate_mota()
        motp = self.calculate_motp()
        idf1 = self.calculate_idf1()
        
        summary = {
            'MOTA': mota,
            'MOTP': motp,
            'IDF1': idf1,
            'ID_Switches': self.frame_metrics['id_switches'],
            'Fragmentations': self.frame_metrics['fragmentations'],
            'True_Positives': self.frame_metrics['true_positives'],
            'False_Positives': self.frame_metrics['false_positives'],
            'False_Negatives': self.frame_metrics['false_negatives'],
            'Total_Frames': self.current_frame,
            'Avg_Track_Length': np.mean(list(self.track_lengths.values())) if self.track_lengths else 0,
        }
        
        return summary
    
    def print_summary(self):
        """è©•ä¾¡ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""
        summary = self.get_summary()
        
        print("\n" + "="*60)
        print("MOT Evaluation Summary")
        print("="*60)
        print(f"Total Frames: {summary['Total_Frames']}")
        print(f"\nCore Metrics:")
        print(f"  MOTA (â†‘):  {summary['MOTA']:.4f}")
        print(f"  MOTP (â†“):  {summary['MOTP']:.2f} pixels")
        print(f"  IDF1 (â†‘):  {summary['IDF1']:.4f}")
        print(f"\nDetection Metrics:")
        print(f"  True Positives:  {summary['True_Positives']}")
        print(f"  False Positives: {summary['False_Positives']}")
        print(f"  False Negatives: {summary['False_Negatives']}")
        print(f"\nTracking Quality:")
        print(f"  ID Switches:     {summary['ID_Switches']}")
        print(f"  Fragmentations:  {summary['Fragmentations']}")
        print(f"  Avg Track Length: {summary['Avg_Track_Length']:.1f} frames")
        print("="*60 + "\n")
        
        return summary
    
    def save_results(self, output_path):
        """è©•ä¾¡çµæœã‚’JSONå½¢å¼ã§ä¿å­˜"""
        summary = self.get_summary()
        
        with open(output_path, 'w') as f:
            json.dump(summary, f, indent=2)
        
        print(f"Evaluation results saved to {output_path}")