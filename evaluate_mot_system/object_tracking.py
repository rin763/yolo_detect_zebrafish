import cv2
import numpy as np
from ultralytics import YOLO
from collections import deque
import os
import torch
from lstm_kalman_tracker import LSTMKalmanTracker
from mot_evaluator import MOTEvaluator
import json

class ObjectTracker:
    def __init__(self, model_path, sequence_length=10, max_fish=20, use_lstm=True, enable_evaluation=False):
        # YOLOãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ï¼ˆmodel_pathãŒNoneã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰
        if model_path is not None:
            self.yolo = YOLO(model_path)
        else:
            self.yolo = None
        
        self.sequence_length = sequence_length
        self.max_fish = max_fish
        self.use_lstm = use_lstm
        
        # ===== è¿½åŠ : è©•ä¾¡æ©Ÿèƒ½ =====
        self.enable_evaluation = enable_evaluation
        if self.enable_evaluation:
            self.evaluator = MOTEvaluator(iou_threshold=0.5, distance_threshold=50)
            print("MOT Evaluator initialized")
        # ==========================
        
        # LSTM+ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿å¼·åŒ–ãƒˆãƒ©ãƒƒã‚«ãƒ¼ã®åˆæœŸåŒ–
        if self.use_lstm:
            device = 'cuda' if torch.cuda.is_available() else 'cpu'
            self.lstm_kalman_tracker = LSTMKalmanTracker(
                sequence_length=sequence_length,
                device=device
            )
            print(f"LSTM+Kalman tracker initialized on {device}")
        
        # ç‰©ä½“ã®è¿½è·¡å±¥æ­´ã‚’ä¿å­˜
        self.track_history = {}
        
        # IDã”ã¨ã®ä½ç½®å±¥æ­´ã‚’ä¿å­˜ï¼ˆx, yåº§æ¨™ã€å‹•ãã®æ–¹å‘ï¼‰
        self.position_history = {}  # {track_id: [(frame_id, x, y, source, direction_rad), ...]}
        
        # æ”¹å–„ã•ã‚ŒãŸIDç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
        self.next_id = 1  # æ¬¡ã®æ–°ã—ã„ID
        self.active_tracks = {}  # ç¾åœ¨è¿½è·¡ä¸­ã®ç‰©ä½“ã¨ãã®ID
        self.missed_frames = {}  # ç‰©ä½“ã‚’è¦‹å¤±ã£ãŸãƒ•ãƒ¬ãƒ¼ãƒ æ•°ã‚’è¨˜éŒ²
        
        # è¦‹å¤±ã£ãŸé­šã®æƒ…å ±ã‚’è¨˜æ†¶ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ 
        self.lost_fish = {}  # {id: {'last_position': [x, y, w, h], 'lost_frames': count, 'last_seen_frame': frame_id}}
        self.reuse_distance_threshold = 250  # IDå†åˆ©ç”¨ã®è·é›¢é–¾å€¤
        self.max_lost_frames = 60  # IDã‚’ä¿æŒã™ã‚‹æœ€å¤§ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ï¼ˆ60ã‹ã‚‰30ã«çŸ­ç¸®ï¼‰
        
        self.reuse_score_threshold = 0.15  # ã‚¹ã‚³ã‚¢é–¾å€¤ï¼ˆç·©ã„ï¼‰
        self.lstm_prediction_range = 100  # LSTMäºˆæ¸¬ç¯„å›²
        self.distance_score_weight = 0.6  # è·é›¢ã®é‡ã¿
        self.lstm_score_weight = 0.4  # LSTMã®é‡ã¿
        
        # ç ´æ£„ã•ã‚ŒãŸIDã‚’è¨˜éŒ²ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ï¼ˆä½ç½®æƒ…å ±ã‚‚å«ã‚€ï¼‰
        self.discarded_ids = {}  # {id: {'position': [x, y], 'discarded_frame': frame_id}}
        self.max_discarded_ids = 20  # è¨˜éŒ²ã™ã‚‹æœ€å¤§ç ´æ£„IDæ•°
        self.discarded_id_reuse_distance = 100  # ç ´æ£„IDå†åˆ©ç”¨ã®è·é›¢é–¾å€¤
        
        
        # å‹•ãã®æ–¹å‘ãƒ™ãƒ¼ã‚¹ãƒãƒƒãƒãƒ³ã‚°ã®è¨­å®š
        self.use_direction_matching = True  # å‹•ãã®æ–¹å‘ã‚’è€ƒæ…®ã—ãŸãƒãƒƒãƒãƒ³ã‚°ã‚’ä½¿ç”¨ã™ã‚‹ã‹
        self.direction_weight = 0.2  # æ–¹å‘ã®é‡ã¿ï¼ˆ0.0-1.0ï¼‰
        self.distance_weight = 0.8  # è·é›¢ã®é‡ã¿ï¼ˆ0.0-1.0ï¼‰
        self.direction_threshold = 1.0  # æ–¹å‘å·®ã®é–¾å€¤ï¼ˆãƒ©ã‚¸ã‚¢ãƒ³ï¼‰
        
        # LSTMå¼·åŒ–ãƒãƒƒãƒãƒ³ã‚°ã®è¨­å®š
        self.lstm_matching_threshold = 0.6  # LSTMãƒãƒƒãƒãƒ³ã‚°ã®é–¾å€¤
        self.prediction_weight = 0.5  # äºˆæ¸¬ã®é‡ã¿
        
    
    def update_position_history(self, track_id, frame_id, x, y, source="detection"):
        """IDã”ã¨ã®ä½ç½®å±¥æ­´ã‚’æ›´æ–°ï¼ˆå‹•ãã®æ–¹å‘ã‚‚è¨ˆç®—ï¼‰"""
        if track_id not in self.position_history:
            self.position_history[track_id] = []
        
        # å‹•ãã®æ–¹å‘ã‚’è¨ˆç®—
        direction_rad = 0.0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
        if len(self.position_history[track_id]) > 0:
            # å‰ã®ä½ç½®ã‚’å–å¾—
            prev_frame, prev_x, prev_y, prev_source, prev_direction = self.position_history[track_id][-1]
            
            # xã¨yã®å·®ã‚’è¨ˆç®—
            dx = x - prev_x
            dy = y - prev_y
            
            # å‹•ããŒã‚ã‚‹å ´åˆã®ã¿æ–¹å‘ã‚’è¨ˆç®—
            if dx != 0 or dy != 0:
                direction_rad = np.arctan2(dy, dx)
                print(f"Track {track_id}: dx={dx:.2f}, dy={dy:.2f}, direction={direction_rad:.3f} rad")
        
        # ä½ç½®å±¥æ­´ã«è¿½åŠ ï¼ˆæ–¹å‘ã‚‚å«ã‚€ï¼‰
        self.position_history[track_id].append((frame_id, x, y, source, direction_rad))
        
        # å±¥æ­´ãŒé•·ã™ãã‚‹å ´åˆã¯å¤ã„ã‚‚ã®ã‚’å‰Šé™¤ï¼ˆãƒ¡ãƒ¢ãƒªç¯€ç´„ï¼‰
        # è©•ä¾¡ç”¨ã«ã‚µã‚¤ã‚ºåˆ¶é™ã‚’ç„¡åŠ¹åŒ–
        # if len(self.position_history[track_id]) > 1000:  # æœ€å¤§1000ãƒ•ãƒ¬ãƒ¼ãƒ åˆ†ä¿æŒ
        #     self.position_history[track_id] = self.position_history[track_id][-500:]  # æœ€æ–°500ãƒ•ãƒ¬ãƒ¼ãƒ åˆ†ã®ã¿ä¿æŒ
    
        
    def get_new_id(self):
        """æ–°ã—ã„IDã‚’å–å¾—ï¼ˆç ´æ£„ã•ã‚ŒãŸIDã‚’å„ªå…ˆçš„ã«å†åˆ©ç”¨ï¼‰"""
        # ç ´æ£„ã•ã‚ŒãŸIDãŒã‚ã‚Œã°å†åˆ©ç”¨
        if self.discarded_ids:
            reused_id = min(self.discarded_ids.keys())  # æœ€å°ã®IDã‚’å†åˆ©ç”¨
            del self.discarded_ids[reused_id]
            print(f"Reusing discarded ID: {reused_id}")
            return reused_id
        
        # ç ´æ£„ã•ã‚ŒãŸIDãŒãªã„å ´åˆã¯æ–°ã—ã„IDã‚’ä½œæˆ
        new_id = self.next_id
        self.next_id += 1
        return new_id
    
    def add_discarded_id(self, fish_id, position, frame_id):
        """ç ´æ£„ã•ã‚ŒãŸIDã‚’è¨˜éŒ²ï¼ˆä½ç½®æƒ…å ±ã‚‚å«ã‚€ï¼‰"""
        self.discarded_ids[fish_id] = {
            'position': position[:2].copy(),  # x, yåº§æ¨™ã®ã¿
            'discarded_frame': frame_id
        }
        
        # æœ€å¤§æ•°ã‚’è¶…ãˆãŸå ´åˆã¯å¤ã„ã‚‚ã®ã‚’å‰Šé™¤
        if len(self.discarded_ids) > self.max_discarded_ids:
            # æœ€ã‚‚å¤ã„IDã‚’å‰Šé™¤
            oldest_id = min(self.discarded_ids.keys(), 
                          key=lambda x: self.discarded_ids[x]['discarded_frame'])
            del self.discarded_ids[oldest_id]
            print(f"Removed oldest discarded ID {oldest_id} from discarded_ids")
        
        print(f"Recorded discarded ID {fish_id} at position {position[:2]}")
    
    def find_nearest_discarded_id(self, new_position):
        """æ–°ã—ã„ä½ç½®ã«æœ€ã‚‚è¿‘ã„ç ´æ£„IDã‚’æ¤œç´¢"""
        if not self.discarded_ids:
            return None
        
        min_distance = float('inf')
        nearest_id = None
        
        for discarded_id, info in self.discarded_ids.items():
            discarded_position = info['position']
            distance = np.linalg.norm(np.array(new_position[:2]) - np.array(discarded_position))
            
            if distance < self.discarded_id_reuse_distance and distance < min_distance:
                min_distance = distance
                nearest_id = discarded_id
        
        if nearest_id is not None:
            print(f"Found nearest discarded ID {nearest_id} at distance {min_distance:.2f}")
            return nearest_id, min_distance
        else:
            return None
    
    def get_last_direction(self, track_id):
        """æŒ‡å®šã•ã‚ŒãŸãƒˆãƒ©ãƒƒã‚¯ã®æœ€å¾Œã®å‹•ãã®æ–¹å‘ã‚’å–å¾—"""
        if track_id not in self.position_history or len(self.position_history[track_id]) < 2:
            return None
        
        # æœ€å¾Œã®2ã¤ã®ä½ç½®ã‹ã‚‰æ–¹å‘ã‚’è¨ˆç®—
        last_positions = self.position_history[track_id][-2:]
        prev_frame, prev_x, prev_y, prev_source, prev_direction = last_positions[0]
        curr_frame, curr_x, curr_y, curr_source, curr_direction = last_positions[1]
        
        # å®Ÿéš›ã®ç§»å‹•ã‹ã‚‰æ–¹å‘ã‚’å†è¨ˆç®—ï¼ˆã‚ˆã‚Šæ­£ç¢ºï¼‰
        dx = curr_x - prev_x
        dy = curr_y - prev_y
        
        if dx == 0 and dy == 0:
            return 0.0
        
        return np.arctan2(dy, dx)
    
    def compute_direction_difference(self, dir1, dir2):
        """2ã¤ã®æ–¹å‘ã®å·®ã‚’è¨ˆç®—ï¼ˆ-Ï€ã‹ã‚‰Ï€ã®ç¯„å›²ã§æ­£è¦åŒ–ï¼‰"""
        if dir1 is None or dir2 is None:
            return float('inf')
        
        diff = dir1 - dir2
        
        # -Ï€ã‹ã‚‰Ï€ã®ç¯„å›²ã«æ­£è¦åŒ–
        while diff > np.pi:
            diff -= 2 * np.pi
        while diff < -np.pi:
            diff += 2 * np.pi
        
        return abs(diff)
    
    def compute_enhanced_matching_cost(self, detection, track_id):
        """è·é›¢ã¨æ–¹å‘ã‚’è€ƒæ…®ã—ãŸãƒãƒƒãƒãƒ³ã‚°ã‚³ã‚¹ãƒˆã‚’è¨ˆç®—ï¼ˆLSTMäºˆæ¸¬ã‚‚å«ã‚€ï¼‰"""
        if track_id not in self.track_history or len(self.track_history[track_id]) == 0:
            return float('inf')
        
        # åŸºæœ¬çš„ãªè·é›¢ã‚³ã‚¹ãƒˆ
        old_bbox = self.track_history[track_id][-1]
        distance = np.linalg.norm(detection[:2] - old_bbox[:2])
        
        # è·é›¢ãŒé–¾å€¤ã‚’è¶…ãˆã‚‹å ´åˆã¯é™¤å¤–
        if distance > 200:
            return float('inf')
        
        # æ–¹å‘ã‚³ã‚¹ãƒˆ
        direction_cost = 0.0
        if self.use_direction_matching:
            # æ¤œå‡ºã®äºˆæƒ³æ–¹å‘ã‚’è¨ˆç®—ï¼ˆæœ€å¾Œã®ä½ç½®ã‹ã‚‰ç¾åœ¨ã®ä½ç½®ã¸ï¼‰
            last_positions = self.position_history.get(track_id, [])
            if len(last_positions) >= 1:
                last_frame, last_x, last_y, last_source, last_direction = last_positions[-1]
                dx = detection[0] - last_x
                dy = detection[1] - last_y
                
                if dx != 0 or dy != 0:
                    detection_direction = np.arctan2(dy, dx)
                    track_direction = self.get_last_direction(track_id)
                    
                    if track_direction is not None:
                        direction_diff = self.compute_direction_difference(detection_direction, track_direction)
                        
                        # æ–¹å‘å·®ãŒé–¾å€¤ã‚’è¶…ãˆã‚‹å ´åˆã¯ãƒšãƒŠãƒ«ãƒ†ã‚£
                        if direction_diff > self.direction_threshold:
                            direction_cost = direction_diff * 10  # å¤§ããªãƒšãƒŠãƒ«ãƒ†ã‚£
                        else:
                            direction_cost = direction_diff
        
        # LSTM+ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿äºˆæ¸¬ã‚³ã‚¹ãƒˆï¼ˆLSTMãŒæœ‰åŠ¹ãªå ´åˆï¼‰
        lstm_cost = 0.0
        lstm_confidence = 0.0
        if self.use_lstm and track_id in self.position_history:
            # LSTM+ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒˆãƒ©ãƒƒã‚«ãƒ¼ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’æ›´æ–°
            self.lstm_kalman_tracker.update_track_sequence(track_id, self.position_history[track_id])
            
            # ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰Re-IDã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
            detection_position = detection[:2]
            hybrid_score = self.lstm_kalman_tracker.compute_hybrid_reid_score(track_id, detection_position)
            lstm_confidence = hybrid_score
            
            # ã‚¹ã‚³ã‚¢ãŒä½ã„å ´åˆã¯ãƒšãƒŠãƒ«ãƒ†ã‚£ï¼ˆä¿‚æ•°ã‚’ä¸‹ã’ã¦ç·©å’Œï¼‰
            if hybrid_score < self.lstm_matching_threshold:
                lstm_cost = (self.lstm_matching_threshold - hybrid_score) * 20  # 50ã‹ã‚‰20ã«æ¸›å°‘
        
        # ç·åˆã‚³ã‚¹ãƒˆï¼ˆè·é›¢ã€æ–¹å‘ã€LSTMäºˆæ¸¬ã®é‡ã¿ä»˜ãå’Œï¼‰
        total_cost = (self.distance_weight * distance + 
                     self.direction_weight * direction_cost + 
                     self.prediction_weight * lstm_cost)
        
        return total_cost, distance, direction_cost, lstm_cost, lstm_confidence
        
    def release_id(self, obj_id, current_frame):
        """IDã‚’è§£æ”¾ã—ã€è¦‹å¤±ã£ãŸé­šã¨ã—ã¦è¨˜éŒ²ï¼ˆ30ãƒ•ãƒ¬ãƒ¼ãƒ ä»¥ä¸Šè¦‹å¤±ã£ãŸå ´åˆï¼‰"""
        if obj_id in self.active_tracks:
            # è¦‹å¤±ã£ãŸé­šã®æƒ…å ±ã‚’ä¿å­˜
            self.lost_fish[obj_id] = {
                'last_position': self.active_tracks[obj_id].copy(),
                'lost_frames': 0,
                'last_seen_frame': current_frame,
                'predicted_positions': []  # LSTMäºˆæ¸¬ä½ç½®ã‚’ä¿å­˜
            }
            
            # LSTM+ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿äºˆæ¸¬ä½ç½®ã‚’è¨ˆç®—ï¼ˆè¦‹å¤±ã£ãŸé­šã®è¿½è·¡ç¶™ç¶šï¼‰
            if self.use_lstm and obj_id in self.position_history:
                predicted_positions = self.lstm_kalman_tracker.predict_lost_track_positions(obj_id, frames_ahead=10)
                self.lost_fish[obj_id]['predicted_positions'] = predicted_positions
                print(f"Generated {len(predicted_positions)} hybrid predicted positions for lost fish {obj_id}")
            
            # ç ´æ£„ã•ã‚ŒãŸIDã¨ã—ã¦ä½ç½®æƒ…å ±ã‚‚è¨˜éŒ²
            self.add_discarded_id(obj_id, self.active_tracks[obj_id], current_frame)
            
            del self.active_tracks[obj_id]
        if obj_id in self.missed_frames:
            del self.missed_frames[obj_id]
        if obj_id in self.track_history:
            del self.track_history[obj_id]
        # ä½ç½®å±¥æ­´ã¯ä¿æŒï¼ˆåˆ†æç”¨ï¼‰
        # if obj_id in self.position_history:
        #     del self.position_history[obj_id]
    
    def find_reusable_id(self, new_position, current_frame):
        """è¦‹å¤±ã£ãŸé­šã®ä¸­ã§å†åˆ©ç”¨å¯èƒ½ãªIDã‚’æ¢ã™ï¼ˆç·©å’Œç‰ˆï¼‰"""
        reusable_id = None
        min_distance = float('inf')
        best_total_score = 0.0
        
        for fish_id, fish_info in list(self.lost_fish.items()):
            # ä¿æŒæœŸé–“ãƒã‚§ãƒƒã‚¯ï¼ˆ60ãƒ•ãƒ¬ãƒ¼ãƒ ã«å»¶é•·ï¼‰
            if fish_info['lost_frames'] > self.max_lost_frames:
                del self.lost_fish[fish_id]
                self.add_discarded_id(fish_id, fish_info['last_position'], fish_info['last_seen_frame'])
                continue
            
            # è·é›¢è¨ˆç®—
            last_pos = fish_info['last_position']
            distance = np.linalg.norm(np.array(new_position[:2]) - np.array(last_pos[:2]))
            
            # è·é›¢ã‚¹ã‚³ã‚¢ï¼ˆç·©å’Œç‰ˆï¼šé–¾å€¤ã‚’è¶…ãˆã¦ã‚‚é™¤å¤–ã—ãªã„ï¼‰
            if distance < self.reuse_distance_threshold:
                distance_score = 1 - (distance / self.reuse_distance_threshold)
            else:
                # é–¾å€¤ã®2å€ã¾ã§ã¯å°‘ã—ã‚¹ã‚³ã‚¢ã‚’ä¸ãˆã‚‹
                distance_score = max(0, 0.3 * (1 - distance / (self.reuse_distance_threshold * 2)))
            
            # LSTMäºˆæ¸¬ã‚¹ã‚³ã‚¢
            lstm_score = 0.0
            if self.use_lstm and 'predicted_positions' in fish_info and fish_info['predicted_positions']:
                min_pred_distance = float('inf')
                for pred_pos in fish_info['predicted_positions']:
                    pred_distance = np.linalg.norm(np.array(new_position[:2]) - pred_pos)
                    min_pred_distance = min(min_pred_distance, pred_distance)
                
                # LSTMäºˆæ¸¬ç¯„å›²ã‚’æ‹¡å¤§ï¼ˆ50 â†’ 100ï¼‰
                if min_pred_distance < self.lstm_prediction_range:
                    lstm_score = max(0, 1 - min_pred_distance / self.lstm_prediction_range)
            
            # ç·åˆã‚¹ã‚³ã‚¢ï¼ˆé‡ã¿èª¿æ•´ï¼‰
            total_score = (self.distance_score_weight * distance_score + 
                        self.lstm_score_weight * lstm_score)
            
            # é–¾å€¤åˆ¤å®šï¼ˆ0.3 â†’ 0.15ã«ç·©å’Œï¼‰
            if total_score > self.reuse_score_threshold:
                if reusable_id is None or total_score > best_total_score:
                    min_distance = distance
                    reusable_id = fish_id
                    best_total_score = total_score
        
        if reusable_id is not None:
            print(f"Found reusable ID {reusable_id} with distance {min_distance:.2f} and score {best_total_score:.3f}")
        
        return reusable_id
    
    def preprocess_detection(self, detection):
        # YOLOã®æ¤œå‡ºçµæœã‚’LSTMã®å…¥åŠ›å½¢å¼ã«å¤‰æ›
        x, y, w, h = detection
        return np.array([x, y, w, h])
    
    def update_tracking(self, frame_id, detections, ground_truth=None):
        """
        è¿½è·¡ã‚’æ›´æ–°ï¼ˆæ—¢å­˜ã®ãƒ­ã‚¸ãƒƒã‚¯ã¯å¤‰æ›´ãªã—ã€è©•ä¾¡æ©Ÿèƒ½ã®ã¿è¿½åŠ ï¼‰
        
        Args:
            frame_id: ãƒ•ãƒ¬ãƒ¼ãƒ ID
            detections: YOLOæ¤œå‡ºçµæœ
            ground_truth: Ground Truthãƒ‡ãƒ¼ã‚¿ï¼ˆè©•ä¾¡ç”¨ã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        """
        # è¦‹å¤±ã£ãŸé­šã®ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ã‚’æ›´æ–°ï¼ˆ30ãƒ•ãƒ¬ãƒ¼ãƒ ä»¥ä¸Šè¦‹å¤±ã£ãŸå ´åˆï¼‰
        for fish_id in self.lost_fish:
            self.lost_fish[fish_id]['lost_frames'] += 1
        
        # ç¾åœ¨ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã§æ¤œå‡ºã•ã‚ŒãŸç‰©ä½“ã®IDã‚’è¨˜éŒ²
        current_detections = set()
        
        for det in detections:
            # ç‰©ä½“ã®ä½ç½®æƒ…å ±ã‚’å–å¾—
            bbox = det.xywh[0].cpu().numpy()  # x, y, w, h
            
            # æ—¢å­˜ã®è¿½è·¡ã¨ãƒãƒƒãƒãƒ³ã‚°ï¼ˆè·é›¢ã¨æ–¹å‘ã‚’è€ƒæ…®ï¼‰
            matched = False
            min_cost = float('inf')
            best_match_id = None
            
            for track_id, track_info in list(self.active_tracks.items()):
                if track_id in current_detections:
                    continue
                
                # è·é›¢ã¨æ–¹å‘ã‚’è€ƒæ…®ã—ãŸãƒãƒƒãƒãƒ³ã‚°ã‚³ã‚¹ãƒˆã‚’è¨ˆç®—
                if self.use_direction_matching:
                    cost_result = self.compute_enhanced_matching_cost(bbox, track_id)
                    if isinstance(cost_result, tuple) and len(cost_result) >= 5:
                        total_cost, distance, direction_cost, lstm_cost, lstm_confidence = cost_result
                    else:
                        total_cost = cost_result
                        distance = float('inf')
                        direction_cost = 0.0
                        lstm_cost = 0.0
                        lstm_confidence = 0.0
                    
                    if total_cost < min_cost:
                        min_cost = total_cost
                        best_match_id = track_id
                        print(f"Enhanced matching: Track {track_id}, cost={total_cost:.2f}, distance={distance:.2f}, direction_cost={direction_cost:.3f}, LSTM_cost={lstm_cost:.3f}, LSTM_confidence={lstm_confidence:.3f}")
                else:
                    # å¾“æ¥ã®è·é›¢ãƒ™ãƒ¼ã‚¹ãƒãƒƒãƒãƒ³ã‚°
                    if track_id in self.track_history and len(self.track_history[track_id]) > 0:
                        old_bbox = self.track_history[track_id][-1]
                        distance = np.linalg.norm(bbox[:2] - old_bbox[:2])
                
                        if distance < 200 and distance < min_cost:
                            min_cost = distance
                            best_match_id = track_id
            
            # æœ€é©ãªãƒãƒƒãƒã‚’è¦‹ã¤ã‘ãŸå ´åˆï¼ˆè·é›¢ã¨æ–¹å‘ã‚’è€ƒæ…®ã€ã‚³ã‚¹ãƒˆãŒé–¾å€¤ä»¥å†…ã®å ´åˆã®ã¿ï¼‰
            if best_match_id is not None and min_cost < 150:  # ã‚³ã‚¹ãƒˆé–¾å€¤ã‚’è¿½åŠ 
                current_detections.add(best_match_id)
                matched = True
                self.missed_frames[best_match_id] = 0
                self.track_history[best_match_id].append(self.preprocess_detection(bbox))
                self.active_tracks[best_match_id] = bbox
                # ä½ç½®å±¥æ­´ã«è¿½åŠ ï¼ˆå‹•ãã®æ–¹å‘ã‚‚è¨ˆç®—ã•ã‚Œã‚‹ï¼‰
                self.update_position_history(best_match_id, frame_id, bbox[0], bbox[1], "detection")
                print(f"Matched detection to track {best_match_id} with enhanced matching (cost: {min_cost:.2f})")
            elif best_match_id is not None:
                print(f"Match found but cost too high: {min_cost:.2f}, skipping match")
            
            # æ—¢å­˜ã®è¿½è·¡ã«ãƒãƒƒãƒã—ãªã‹ã£ãŸå ´åˆã€è¦‹å¤±ã£ãŸé­šã®IDã‚’å†åˆ©ç”¨ï¼ˆ200ãƒ”ã‚¯ã‚»ãƒ«ä»¥å†…ï¼‰
            if not matched:
                reusable_id = self.find_reusable_id(bbox, frame_id)
                if reusable_id is not None:
                    # è¦‹å¤±ã£ãŸé­šã®IDã‚’å†åˆ©ç”¨ï¼ˆ200ãƒ”ã‚¯ã‚»ãƒ«ä»¥å†…ï¼‰
                    current_detections.add(reusable_id)
                    self.active_tracks[reusable_id] = bbox
                    self.track_history[reusable_id] = deque(maxlen=self.sequence_length)
                    self.track_history[reusable_id].append(self.preprocess_detection(bbox))
                    self.missed_frames[reusable_id] = 0
                    # è¦‹å¤±ã£ãŸé­šãƒªã‚¹ãƒˆã‹ã‚‰å‰Šé™¤
                    del self.lost_fish[reusable_id]
                    # ä½ç½®å±¥æ­´ã«è¿½åŠ ï¼ˆå‹•ãã®æ–¹å‘ã‚‚è¨ˆç®—ã•ã‚Œã‚‹ï¼‰
                    self.update_position_history(reusable_id, frame_id, bbox[0], bbox[1], "detection")
                    print(f"Reused ID {reusable_id} for fish near position {bbox[:2]}")
                else:
                    # ç ´æ£„ã•ã‚ŒãŸIDã®å†åˆ©ç”¨ã‚’è©¦è¡Œ
                    result = self.find_nearest_discarded_id(bbox)
                    if result is not None:
                        nearest_discarded_id, distance = result
                        # ç ´æ£„ã•ã‚ŒãŸIDã‚’å†åˆ©ç”¨
                        del self.discarded_ids[nearest_discarded_id]
                        print(f"Reusing discarded ID {nearest_discarded_id} for new detection at distance {distance:.2f}")
                        
                        # ç ´æ£„ã•ã‚ŒãŸIDã§å†ä½œæˆ
                        current_detections.add(nearest_discarded_id)
                        self.active_tracks[nearest_discarded_id] = bbox
                        self.track_history[nearest_discarded_id] = deque(maxlen=self.sequence_length)
                        self.track_history[nearest_discarded_id].append(self.preprocess_detection(bbox))
                        self.missed_frames[nearest_discarded_id] = 0
                        # ä½ç½®å±¥æ­´ã«è¿½åŠ ï¼ˆå‹•ãã®æ–¹å‘ã‚‚è¨ˆç®—ã•ã‚Œã‚‹ï¼‰
                        self.update_position_history(nearest_discarded_id, frame_id, bbox[0], bbox[1], "detection")
                        print(f"Reused discarded ID {nearest_discarded_id} for fish at position {bbox[:2]}")
                    else:
                        # æ–°ã—ã„IDã‚’ä½œæˆï¼ˆç ´æ£„ã•ã‚ŒãŸIDã‚’å„ªå…ˆçš„ã«å†åˆ©ç”¨ï¼‰
                        new_id = self.get_new_id()
                        current_detections.add(new_id)
                        self.active_tracks[new_id] = bbox
                        self.track_history[new_id] = deque(maxlen=self.sequence_length)
                        self.track_history[new_id].append(self.preprocess_detection(bbox))
                        self.missed_frames[new_id] = 0
                        # ä½ç½®å±¥æ­´ã«è¿½åŠ ï¼ˆå‹•ãã®æ–¹å‘ã‚‚è¨ˆç®—ã•ã‚Œã‚‹ï¼‰
                        self.update_position_history(new_id, frame_id, bbox[0], bbox[1], "detection")
                        print(f"Created new ID {new_id} for fish at position {bbox[:2]}")
        
        # è¦‹å¤±ã£ãŸç‰©ä½“ã®å‡¦ç†ï¼ˆ30ãƒ•ãƒ¬ãƒ¼ãƒ ä»¥ä¸Šè¦‹å¤±ã£ãŸå ´åˆï¼‰ 
        for track_id in list(self.active_tracks.keys()):
            if track_id not in current_detections:
                self.missed_frames[track_id] = self.missed_frames.get(track_id, 0) + 1
                
                
                if self.missed_frames[track_id] > 30:  # 30ãƒ•ãƒ¬ãƒ¼ãƒ ä»¥ä¸Šè¦‹å¤±ã£ãŸå ´åˆ
                    missed_count = self.missed_frames[track_id]
                    self.release_id(track_id, frame_id)
                    print(f"Lost fish ID {track_id} after {missed_count} frames")
                    
                    # LSTM+ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒˆãƒ©ãƒƒã‚«ãƒ¼ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                    if self.use_lstm:
                        self.lstm_kalman_tracker.cleanup_track(track_id)
        
        # ===== è¿½åŠ : è©•ä¾¡æ©Ÿèƒ½ =====
        # Ground TruthãŒã‚ã‚‹å ´åˆã€è©•ä¾¡å™¨ã‚’æ›´æ–°
        if self.enable_evaluation and ground_truth is not None:
            # ç¾åœ¨ã®ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°çµæœã‚’è©•ä¾¡ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¤‰æ›
            predictions = {}
            for track_id, bbox in self.active_tracks.items():
                # bboxå½¢å¼: [x_center, y_center, width, height]
                predictions[track_id] = [bbox[0], bbox[1], bbox[2], bbox[3]]
            
            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±
            if frame_id % 100 == 0:  # 100ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã«è¡¨ç¤º
                print(f"ğŸ“Š Frame {frame_id}: GT objects={len(ground_truth)}, Predictions={len(predictions)}")
            
            # è©•ä¾¡å™¨ã‚’æ›´æ–°
            self.evaluator.update_frame(ground_truth, predictions)
        elif self.enable_evaluation and ground_truth is None:
            if frame_id % 100 == 0:
                print(f"âš ï¸ Frame {frame_id}: No Ground Truth data available")
        # ==========================

    # ===== è¿½åŠ : Ground Truthèª­ã¿è¾¼ã¿é–¢æ•° =====
    def load_ground_truth(self, gt_path, frame_id):
        """
        MOTChallengeå½¢å¼ã®Ground Truthã‚’èª­ã¿è¾¼ã¿
        å½¢å¼: frame, id, x, y, w, h, conf, -1, -1, -1
        
        Args:
            gt_path: Ground Truthãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            frame_id: ç¾åœ¨ã®ãƒ•ãƒ¬ãƒ¼ãƒ ID
            
        Returns:
            dict: {obj_id: [x_center, y_center, width, height]}
        """
        gt_data = {}
        
        if not os.path.exists(gt_path):
            print(f"âš ï¸ Ground Truth file not found: {gt_path}")
            return None
        
        try:
            with open(gt_path, 'r') as f:
                lines = f.readlines()
                if not lines:
                    print(f"âš ï¸ Ground Truth file is empty: {gt_path}")
                    return None
                
                for line in lines:
                    parts = line.strip().split(',')
                    if len(parts) < 6:
                        continue
                    
                    try:
                        frame_num = int(parts[0])
                        if frame_num == frame_id:
                            obj_id = int(parts[1])
                            x, y, w, h = map(float, parts[2:6])
                            # å·¦ä¸Šè§’åº§æ¨™ã‹ã‚‰ä¸­å¿ƒåº§æ¨™ã«å¤‰æ›
                            gt_data[obj_id] = [x + w/2, y + h/2, w, h]
                    except ValueError as ve:
                        print(f"âš ï¸ Invalid data format in line: {line.strip()}")
                        continue
                        
        except Exception as e:
            print(f"âŒ Error loading ground truth: {e}")
            import traceback
            traceback.print_exc()
            return None
        
        return gt_data if gt_data else None
    # ==========================================

    def process_video(self, video_path, ground_truth_path=None):
        """
        å‹•ç”»ã‚’å‡¦ç†ï¼ˆæ—¢å­˜ã®ãƒ­ã‚¸ãƒƒã‚¯ã¯å¤‰æ›´ãªã—ã€è©•ä¾¡æ©Ÿèƒ½ã®ã¿è¿½åŠ ï¼‰
        
        Args:
            video_path: å…¥åŠ›å‹•ç”»ã®ãƒ‘ã‚¹
            ground_truth_path: Ground Truthãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        """
        # ===== è©•ä¾¡è¨­å®šã®ç¢ºèª =====
        print("\n" + "="*60)
        print("ğŸ¬ Video Processing & Tracking")
        print("="*60)
        print(f"ğŸ“¹ Video: {video_path}")
        print(f"ğŸ”§ LSTM Enabled: {self.use_lstm}")
        print(f"ğŸ“Š Evaluation Enabled: {self.enable_evaluation}")
        
        if self.enable_evaluation:
            if ground_truth_path:
                if os.path.exists(ground_truth_path):
                    print(f"âœ… Ground Truth: {ground_truth_path}")
                    # Ground Truthãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’ãƒã‚§ãƒƒã‚¯
                    try:
                        with open(ground_truth_path, 'r') as f:
                            lines = f.readlines()
                            print(f"   Total lines in GT file: {len(lines)}")
                            if lines:
                                # æœ€åˆã¨æœ€å¾Œã®ãƒ•ãƒ¬ãƒ¼ãƒ IDã‚’è¡¨ç¤º
                                first_frame = int(lines[0].strip().split(',')[0])
                                last_frame = int(lines[-1].strip().split(',')[0])
                                print(f"   Frame range: {first_frame} - {last_frame}")
                    except Exception as e:
                        print(f"âš ï¸ Error reading GT file: {e}")
                else:
                    print(f"âŒ Ground Truth file not found: {ground_truth_path}")
                    print("   Evaluation will be disabled!")
                    self.enable_evaluation = False
            else:
                print("âŒ No Ground Truth path provided")
                print("   Evaluation will be disabled!")
                self.enable_evaluation = False
        print("="*60 + "\n")
        # ==========================
        
        cap = cv2.VideoCapture(video_path)
        
        # å‹•ç”»ã®è¨­å®šã‚’å–å¾—
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        
        # å‡ºåŠ›ç”¨ã®VideoWriterã‚’è¨­å®š
        output_path = "video/tracking_video_right.mp4"
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
        
        frame_count = 0
        
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
            
            frame_count += 1
                
            # YOLOã§ç‰©ä½“æ¤œå‡º
            results = self.yolo.track(frame, persist=True)
            
            # YOLOæ¤œå‡ºçµæœã‚’å‡¦ç†
            detections = []
            if results[0].boxes is not None:
                detections.extend(results[0].boxes)
            
            # ===== è¿½åŠ : Ground Truthèª­ã¿è¾¼ã¿ =====
            ground_truth = None
            if self.enable_evaluation and ground_truth_path is not None:
                ground_truth = self.load_ground_truth(ground_truth_path, frame_count)
            # ======================================
            
            if detections:
                # è¿½è·¡ã®æ›´æ–°ï¼ˆGround Truthã‚‚æ¸¡ã™ï¼‰
                self.update_tracking(frame_count, detections, ground_truth)
                
                # çµæœã®å¯è¦–åŒ–
                used_ids = set()  # ã“ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã§ä½¿ç”¨æ¸ˆã¿ã®IDã‚’è¨˜éŒ²
                for box in detections:
                    # YOLOæ¤œå‡ºã®å¯è¦–åŒ–
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    # ç‰©ä½“ã®ä¸­å¿ƒåº§æ¨™ã‚’è¨ˆç®—
                    center_x = (x1 + x2) / 2
                    center_y = (y1 + y2) / 2
                    
                    # æœ€ã‚‚è¿‘ã„è¿½è·¡IDã‚’æ¢ã™ï¼ˆä½¿ç”¨æ¸ˆã¿ã®IDã¯é™¤å¤–ï¼‰
                    min_distance = float('inf')
                    closest_id = None
                    
                    for track_id, track_info in self.active_tracks.items():
                        if track_id in used_ids:  # ä½¿ç”¨æ¸ˆã¿ã®IDã¯ã‚¹ã‚­ãƒƒãƒ—
                            continue
                        distance = np.linalg.norm(np.array([center_x, center_y]) - track_info[:2])
                        if distance < min_distance:
                            min_distance = distance
                            closest_id = track_id
                    
                    if closest_id is not None:
                        used_ids.add(closest_id)  # ä½¿ç”¨ã—ãŸIDã‚’è¨˜éŒ²
                        # BBoxã‚’ç·‘è‰²ã§è¡¨ç¤º
                        cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)
                        # IDã‚’é’è‰²ã§è¡¨ç¤º
                        cv2.putText(frame, f"{closest_id}", 
                                  (int(x1), int(y1)-10), 
                                  cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)
            
            # ===== è¿½åŠ : è©•ä¾¡æƒ…å ±ã‚’ç”»é¢ã«è¡¨ç¤º =====
            if self.enable_evaluation:
                summary = self.evaluator.get_summary()
                # ãƒ•ãƒ¬ãƒ¼ãƒ æƒ…å ±
                cv2.putText(frame, f"Frame: {frame_count}", (10, 30), 
                          cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                # IDåˆ‡ã‚Šæ›¿ã‚ã‚Šå›æ•°
                cv2.putText(frame, f"ID Switches: {summary['ID_Switches']}", (10, 60), 
                          cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)
                # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªãƒˆãƒ©ãƒƒã‚¯æ•°
                cv2.putText(frame, f"Active Tracks: {len(self.active_tracks)}", (10, 90), 
                          cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
            # =========================================
            
            # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿
            out.write(frame)
            
            # çµæœã®è¡¨ç¤º
            cv2.imshow("Tracking", frame)
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
                
        cap.release()
        out.release()
        cv2.destroyAllWindows()
        print(f"Tracking result saved to {output_path}")
        
        # ===== è¿½åŠ : è©•ä¾¡çµæœã®è¡¨ç¤ºã¨ä¿å­˜ =====
        if self.enable_evaluation:
            print("\n" + "="*60)
            print("MOT Evaluation Results")
            print("="*60)
            summary = self.evaluator.print_summary()
            
            # JSONãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
            result_dir = os.path.dirname(output_path)
            if not result_dir:
                result_dir = "."
            json_path = os.path.join(result_dir, "evaluation_results.json")
            self.evaluator.save_results(json_path)
            
            return summary
        # ======================================
        
        return None

    def collect_training_data(self, video_path, output_dir):
        """
        å‹•ç”»ã‹ã‚‰æ•™å¸«ãƒ‡ãƒ¼ã‚¿ã‚’è‡ªå‹•ç”Ÿæˆ
        """
        os.makedirs(output_dir, exist_ok=True)
        cap = cv2.VideoCapture(video_path)
        frame_count = 0
        track_data = {}  # ç‰©ä½“IDã”ã¨ã®è¿½è·¡ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
        
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
                
            # YOLOã§ç‰©ä½“æ¤œå‡º
            results = self.yolo.track(frame, persist=True)
            
            if results[0].boxes is not None:
                for box in results[0].boxes:
                    # ç‰©ä½“ã®ä½ç½®æƒ…å ±ã‚’å–å¾—
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    center_x = (x1 + x2) / 2
                    center_y = (y1 + y2) / 2
                    width = x2 - x1
                    height = y2 - y1
                    
                    # ç‰©ä½“ã®IDã‚’å–å¾—
                    obj_id = int(box.id.item()) if box.id is not None else None
                    
                    if obj_id is not None:
                        # è¿½è·¡ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
                        if obj_id not in track_data:
                            track_data[obj_id] = []
                        
                        track_data[obj_id].append([frame_count, center_x, center_y, width, height])
            
            frame_count += 1
            
            # é€²æ—è¡¨ç¤º
            if frame_count % 100 == 0:
                print(f"Processed {frame_count} frames")
        
        # è¿½è·¡ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
        for obj_id, data in track_data.items():
            if len(data) >= self.sequence_length:  # ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã®ã¿ä¿å­˜
                data_array = np.array(data)
                output_path = os.path.join(output_dir, f"track_{obj_id}.npy")
                np.save(output_path, data_array)
                print(f"Saved tracking data for object {obj_id} with {len(data)} frames")
        
        cap.release()
        print(f"Data collection completed. Saved {len(track_data)} object tracks.")


if __name__ == "__main__":
    # ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹ã‚’æŒ‡å®š
    model_path = "/Users/rin/Documents/ç•¢æ¥­å°ˆé¡Œ/yolo_detect_zebrafish/train_results/weights/best.pt"
    
    # å‹•ç”»ã®ãƒ‘ã‚¹ã‚’æŒ‡å®š
    video_path = "/Users/rin/Documents/ç•¢æ¥­å°ˆé¡Œ/YOLO/video/3min_3D_left.mp4"
    
    # Ground Truthã®ãƒ‘ã‚¹ï¼ˆMOTChallengeå½¢å¼ã®.txtãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
    # ä¾‹: "/Users/rin/Documents/ç•¢æ¥­å°ˆé¡Œ/yolo_detect_zebrafish/evaluate_mot_system/ground_truth/semi_auto.txt"
    # ground_truth.pyã¯Ground Truthç”Ÿæˆãƒ„ãƒ¼ãƒ«ã§ã€Ground Truthãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã§ã¯ã‚ã‚Šã¾ã›ã‚“
    ground_truth_path = "/Users/rin/Documents/ç•¢æ¥­å°ˆé¡Œ/yolo_detect_zebrafish/evaluate_mot_system/ground_truth/semi_auto.txt"
    
    # ===== è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰ã®è¨­å®š =====
    # Ground Truthãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰ã‚’æœ‰åŠ¹åŒ–
    enable_evaluation = ground_truth_path is not None and os.path.exists(ground_truth_path)
    
    if not enable_evaluation and ground_truth_path:
        print(f"\nâš ï¸ WARNING: Ground Truth file not found: {ground_truth_path}")
        print("   Evaluation mode will be disabled.")
        print("   Please generate Ground Truth using ground_truth.py first.\n")
    # ===========================
    
    # LSTMå¼·åŒ–ãƒˆãƒ©ãƒƒã‚«ãƒ¼ã®åˆæœŸåŒ–
    tracker = ObjectTracker(
        model_path=model_path,
        sequence_length=10,
        max_fish=20,
        use_lstm=True,  # LSTMæ©Ÿèƒ½ã‚’æœ‰åŠ¹åŒ–
        enable_evaluation=enable_evaluation  # è©•ä¾¡æ©Ÿèƒ½ã‚’æœ‰åŠ¹åŒ–
    )
    
    print("Starting LSTM+Kalman Filter enhanced object tracking...")
    print(f"Using device: {'CUDA' if torch.cuda.is_available() else 'CPU'}")
    print("Hybrid prediction features:")
    print("  - LSTM neural network for pattern learning")
    print("  - Kalman filter for motion prediction")
    print("  - Hybrid Re-ID scoring system")
    print("  - Enhanced lost fish tracking")
    
    if enable_evaluation:
        print("\n=== MOT Evaluation Mode Enabled ===")
        print("Evaluation metrics will be calculated:")
        print("  - MOTA (Multiple Object Tracking Accuracy)")
        print("  - MOTP (Multiple Object Tracking Precision)")
        print("  - IDF1 (ID F1 Score)")
        print("  - ID Switches")
        print("  - Fragmentations")
    
    # å‹•ç”»ã®å‡¦ç†é–‹å§‹
    evaluation_results = tracker.process_video(
        video_path,
        ground_truth_path=ground_truth_path
    )
    
    # ===== è©•ä¾¡çµæœã®è¡¨ç¤º =====
    if evaluation_results:
        print("\n" + "="*60)
        print("Final Evaluation Summary")
        print("="*60)
        print(f"MOTA: {evaluation_results['MOTA']:.4f}")
        print(f"MOTP: {evaluation_results['MOTP']:.2f} pixels")
        print(f"IDF1: {evaluation_results['IDF1']:.4f}")
        print(f"ID Switches: {evaluation_results['ID_Switches']}")
        print(f"Fragmentations: {evaluation_results['Fragmentations']}")
        print("="*60)
    # ==========================